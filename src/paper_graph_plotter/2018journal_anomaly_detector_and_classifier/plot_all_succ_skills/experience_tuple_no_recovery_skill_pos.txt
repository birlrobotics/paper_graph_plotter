[Experience(state=array([ 0.66267058, -0.17519509, -0.08670994,  0.02168133,  0.01400067,
        2.30668839,  0.140227  ]), action=5, reward=-1, next_state=array([ 0.66704285, -0.1809858 , -0.01499797,  0.05075678,  0.10611203,
        2.55302401,  0.10265461]), done=False), Experience(state=array([ 0.50985086, -0.80577048,  0.14469077,  0.01984406,  0.01313349,
        2.61997614,  0.09215669]), action=8, reward=100, next_state=array([ 0.52731956, -0.81715694,  0.13756086,  0.02621686,  0.01293158,
        2.25928219,  0.04804734]), done=True), Experience(state=array([ 0.71418086, -0.09151835, -0.07275655,  0.02768075,  0.01657639,
        2.42112196,  0.05122504]), action=5, reward=-1, next_state=array([ 0.71564639, -0.08990034, -0.07087689,  0.03195515,  0.01782327,
        3.24932774,  0.06633581]), done=False), Experience(state=array([ 0.7463778 , -0.23020492,  0.00724154,  0.02321467,  0.01074327,
        3.56632488,  0.07011862]), action=5, reward=-1, next_state=array([ 0.74476463, -0.23036033,  0.00710365,  0.0233361 ,  0.01533332,
        2.28075635,  0.05224303]), done=False), Experience(state=array([ 0.6532037 , -0.14352944,  0.09000834,  0.03415436,  0.0150896 ,
        2.23839037,  0.06985865]), action=7, reward=-1, next_state=array([ 0.65142134, -0.14112882,  0.08887762,  0.07636597,  0.02140976,
        2.46860761,  0.07493758]), done=False), Experience(state=array([ 0.59812818, -0.2089553 ,  0.01513393,  0.03226032,  0.01818425,
        1.36723568,  0.06654537]), action=4, reward=-1, next_state=array([ 0.58864394, -0.22798604, -0.11337684,  0.03570309,  0.02197178,
        1.42188521,  0.07846087]), done=False), Experience(state=array([ 0.52445287, -0.81967143,  0.03332908,  0.04626307,  0.0250304 ,
        3.28919271,  0.05044421]), action=9, reward=-1, next_state=array([ 0.53018346, -0.81776125,  0.13529404,  0.03294584,  0.01552321,
        1.52049743,  0.04268681]), done=False), Experience(state=array([ 0.62286194, -0.1736153 ,  0.0361214 ,  0.03360963,  0.01813062,
        1.76549347,  0.03603496]), action=4, reward=-1, next_state=array([ 0.62421862, -0.17594904,  0.01919995,  0.09631213,  0.07653189,
        1.1218131 ,  0.03715822]), done=False), Experience(state=array([ 0.52720002, -0.81916026,  0.03397265,  0.03582461,  0.02255236,
        3.46752244,  0.05746874]), action=9, reward=-1, next_state=array([ 0.53100273, -0.82089296,  0.13937187,  0.0521549 ,  0.0257909 ,
        2.12098847,  0.08409245]), done=False), Experience(state=array([ 0.52272837, -0.81970898,  0.12772922,  0.05655042,  0.01879043,
        6.9888941 ,  0.16478286]), action=8, reward=100, next_state=array([ 0.48547251, -0.84973887,  0.04875799,  0.05445737,  0.02741983,
        7.53037474,  0.09837563]), done=True), Experience(state=array([ 0.7727815 , -0.14989759,  0.11625764,  0.03759535,  0.01635183,
        2.259369  ,  0.05490444]), action=7, reward=-1, next_state=array([ 0.77244003, -0.14939616,  0.11640317,  0.02121031,  0.00899763,
        2.37394654,  0.07344783]), done=False), Experience(state=array([ 0.61589568, -0.17745902,  0.11166784,  0.04264477,  0.02068486,
        4.74919811,  0.01809902]), action=7, reward=-1, next_state=array([ 0.57094568, -0.63231688,  0.06228753,  0.03300889,  0.01913844,
        7.64165054,  0.52211222]), done=False), Experience(state=array([ 0.63338322, -0.17863362,  0.11487187,  0.02675229,  0.01229196,
        2.79329359,  0.04034871]), action=7, reward=-1, next_state=array([ 0.57568776, -0.63170316,  0.06625565,  0.0285122 ,  0.02176314,
        6.3056705 ,  0.48474635]), done=False), Experience(state=array([ 0.48427314, -0.84890887,  0.10041392,  0.02017551,  0.01612081,
        4.01025703,  0.07352081]), action=8, reward=100, next_state=array([ 0.53329239, -0.82027944,  0.03941936,  0.04526237,  0.02116507,
        2.45546445,  0.07293013]), done=True), Experience(state=array([ 0.61279964, -0.20222018, -0.03934432,  0.02326844,  0.01294057,
        2.84017682,  0.17751503]), action=5, reward=-1, next_state=array([ 6.00939599e-01, -1.96413380e-01,  1.20518615e-03,  1.25207838e-01,
        9.90939124e-02,  7.08888596e+00,  8.42835215e-02]), done=False), Experience(state=array([ 0.63248636, -0.18972353,  0.05832539,  0.02353538,  0.01171668,
        1.72500765,  0.09524401]), action=4, reward=-1, next_state=array([ 6.50392755e-01, -1.85759371e-01, -5.98961364e-02,  1.70799897e-02,
        1.02197292e-02,  1.31466469e+01,  4.33675774e-01]), done=False), Experience(state=array([ 0.6684408 , -0.17787253,  0.04504366,  0.0434691 ,  0.02350915,
        1.4204011 ,  0.1707656 ]), action=4, reward=-1, next_state=array([ 0.69767501, -0.17998263, -0.03809926,  0.03250332,  0.02145198,
        2.99111512,  0.31142194]), done=False), Experience(state=array([ 0.66470847, -0.15078967,  0.0604423 ,  0.0249528 ,  0.01167219,
        2.36470444,  0.14079693]), action=7, reward=-1, next_state=array([ 0.52846576, -0.47236329,  0.04286353,  0.02722472,  0.01531303,
       11.80710631,  1.40061207]), done=False), Experience(state=array([ 0.7036672 , -0.14842261, -0.0216631 ,  0.03044469,  0.01679742,
        1.35426146,  0.07983195]), action=5, reward=-1, next_state=array([ 0.71797374, -0.1632977 ,  0.03505599,  0.04730739,  0.02825095,
        2.24243895,  0.09233277]), done=False), Experience(state=array([ 0.53190923, -0.81701046,  0.2353309 ,  0.02240702,  0.01517584,
        1.60490158,  0.09259003]), action=8, reward=100, next_state=array([ 0.52956144, -0.81887388,  0.15570462,  0.04945504,  0.0867762 ,
        1.96084288,  0.07391899]), done=True), Experience(state=array([ 0.66458867, -0.16623177,  0.11159118,  0.03743465,  0.01480441,
        2.9639728 ,  0.05874145]), action=7, reward=-1, next_state=array([ 0.63672903, -0.52217188,  0.16803296,  0.40037897,  0.30134548,
        1.97772837,  0.06441832]), done=False), Experience(state=array([ 0.48770715, -0.38303238,  0.11856783,  0.02053898,  0.01209707,
        1.96023438,  0.12432062]), action=3, reward=-1, next_state=array([ 0.48753344, -0.38307314,  0.11849572,  0.03040663,  0.01393482,
        1.28299221,  0.11525852]), done=False), Experience(state=array([ 0.70872096, -0.07584064,  0.04146625,  0.02770714,  0.01636856,
        3.49823558,  0.05879142]), action=7, reward=-1, next_state=array([ 0.71673771, -0.25093191,  0.0600847 ,  0.08077298,  0.05135848,
        2.27921318,  0.07427351]), done=False), Experience(state=array([ 0.63687515, -0.22673973, -0.05911187,  0.02192557,  0.01787665,
        1.92821056,  0.0896168 ]), action=5, reward=-1, next_state=array([ 0.63670635, -0.2274986 , -0.05933828,  0.03441182,  0.02033842,
        3.57534183,  0.20551264]), done=False), Experience(state=array([ 0.77897972, -0.30434487, -0.10033076,  0.0303269 ,  0.02045093,
        3.32836982,  0.054093  ]), action=3, reward=-1, next_state=array([ 0.77374785, -0.30084971,  0.05015131,  0.07356669,  0.0442485 ,
        1.35305697,  0.05947134]), done=False), Experience(state=array([ 0.62389986, -0.25880789,  0.11500412,  0.03427211,  0.01436905,
        4.38885849,  0.09251209]), action=7, reward=-1, next_state=array([ 0.61033703, -0.54195969,  0.15423058,  0.31873513,  0.18566296,
        6.83617367,  0.32147773]), done=False), Experience(state=array([ 0.66513715, -0.12883555, -0.08039302,  0.02228498,  0.0140895 ,
        2.6066983 ,  0.09973917]), action=5, reward=-1, next_state=array([ 0.66235634, -0.14495612,  0.01438844,  0.04551991,  0.11935421,
        5.61531449,  0.08293869]), done=False), Experience(state=array([ 0.72067954, -0.3060269 ,  0.08376541,  0.02386606,  0.01396428,
        3.03385713,  0.0576046 ]), action=4, reward=-1, next_state=array([ 0.74098822, -0.26571571, -0.11595085,  0.07469145,  0.02292172,
        2.82307197,  0.05177286]), done=False), Experience(state=array([ 0.52483695, -0.8206087 ,  0.2314275 ,  0.02635677,  0.01863654,
        2.27700445,  0.1080665 ]), action=8, reward=100, next_state=array([ 0.52763438, -0.8276392 ,  0.10128986,  0.18913912,  0.14038116,
        1.57539753,  0.14075868]), done=True), Experience(state=array([ 0.52705251, -0.81710126,  0.23198262,  0.04392062,  0.02041008,
        2.75776987,  0.11533583]), action=8, reward=100, next_state=array([ 0.52166291, -0.81669428,  0.03202225,  0.03404014,  0.01718551,
        1.99059664,  0.11258972]), done=True), Experience(state=array([ 0.78566425, -0.18948858,  0.04530016,  0.0170892 ,  0.01182867,
        2.10500286,  0.0401881 ]), action=4, reward=-1, next_state=array([ 0.78174353, -0.19240126, -0.11020807,  0.0430144 ,  0.02127442,
        1.57533727,  0.06333885]), done=False), Experience(state=array([ 0.54898935, -0.48021939,  0.21753025,  0.02963555,  0.0174576 ,
        2.05927603,  0.12816369]), action=7, reward=-1, next_state=array([ 0.54906787, -0.48025783,  0.21761719,  0.03072949,  0.01405965,
        2.31559149,  0.13112853]), done=False), Experience(state=array([ 0.61354159, -0.14015335,  0.03896263,  0.02488866,  0.01450064,
        2.86786415,  0.04359897]), action=7, reward=-1, next_state=array([ 0.5565751 , -0.69314455,  0.17672211,  0.0301253 ,  0.01371479,
        5.42570728,  0.62417218]), done=False), Experience(state=array([ 0.75901722, -0.17798177, -0.11116422,  0.02927008,  0.01742741,
        1.79608028,  0.04556151]), action=5, reward=-1, next_state=array([ 0.76164939, -0.17709984, -0.10898956,  0.03626078,  0.02132964,
        1.4811502 ,  0.05396389]), done=False), Experience(state=array([ 0.6537436 , -0.12850899, -0.0642673 ,  0.02353761,  0.01193911,
        3.27839045,  0.05087301]), action=3, reward=-1, next_state=array([ 0.65405747, -0.12868578, -0.06406571,  0.03003371,  0.01720717,
        3.04072618,  0.0432333 ]), done=False), Experience(state=array([ 0.65969082, -0.15039611,  0.10849836,  0.03810632,  0.01855473,
        1.86663408,  0.14784515]), action=4, reward=-1, next_state=array([ 0.66304313, -0.19063348, -0.03400064,  0.03352994,  0.02015677,
        1.08506724,  0.17166379]), done=False), Experience(state=array([ 0.64907616, -0.13778789,  0.15109259,  0.02821652,  0.01647262,
        4.09147039,  0.04605522]), action=7, reward=-1, next_state=array([ 0.63765572, -0.40869071,  0.19248387,  0.3290121 ,  0.32015319,
        5.24239822,  0.29094203]), done=False), Experience(state=array([ 5.09312974e-01, -4.64389165e-01,  6.89198844e-02,  2.24676495e-02,
        6.45330056e-03,  2.86939479e+01,  1.96178700e+00]), action=7, reward=-1, next_state=array([ 5.06154619e-01, -4.63258463e-01,  7.07379236e-02,  2.25430944e-02,
        9.97956787e-03,  2.88628464e+01,  2.02200823e+00]), done=False), Experience(state=array([ 0.65595069, -0.16490743, -0.10269285,  0.03878089,  0.00964576,
        1.00021223,  0.11810794]), action=5, reward=-1, next_state=array([ 0.65742811, -0.13942967, -0.00960536,  0.02893788,  0.01719409,
        1.78147262,  0.09550237]), done=False), Experience(state=array([ 0.65119077, -0.16512661, -0.08720462,  0.02947764,  0.01826088,
        2.98190688,  0.14440322]), action=5, reward=-1, next_state=array([ 0.6475041 , -0.16844072, -0.08185833,  0.04719905,  0.05502088,
        2.34480025,  0.12883632]), done=False), Experience(state=array([ 0.69471648, -0.27754984,  0.14457946,  0.06570031,  0.03915346,
        3.53253051,  0.04362766]), action=7, reward=-1, next_state=array([ 0.67060673, -0.27587759,  0.11744867,  0.02134036,  0.01380932,
        2.40475821,  0.04438126]), done=False), Experience(state=array([ 0.61083891, -0.20218976,  0.11087255,  0.03025217,  0.0156123 ,
        2.82039725,  0.06535128]), action=4, reward=-1, next_state=array([ 0.62456921, -0.20500681, -0.04077408,  0.02865608,  0.01738537,
        3.36311545,  0.07029122]), done=False), Experience(state=array([ 0.6771637 , -0.14121675, -0.02052767,  0.03458876,  0.01852988,
        1.96223314,  0.04763726]), action=5, reward=-1, next_state=array([ 0.68484826, -0.15053572,  0.01314126,  0.04051437,  0.02546062,
        2.65077726,  0.08644653]), done=False), Experience(state=array([ 0.6038144 , -0.20768538, -0.03711336,  0.03357818,  0.01808437,
        3.85165374,  0.26297234]), action=5, reward=-1, next_state=array([ 0.60431997, -0.2073216 , -0.03682311,  0.02697949,  0.01611175,
        3.64093253,  0.30354766]), done=False), Experience(state=array([ 0.52916377, -0.82113069,  0.04226514,  0.02605934,  0.01476096,
        1.52219143,  0.13440004]), action=9, reward=-1, next_state=array([ 0.53297247, -0.8172214 ,  0.13772229,  0.04736451,  0.02228541,
        1.74791788,  0.14424037]), done=False), Experience(state=array([ 0.68095613, -0.19937756, -0.12071982,  0.02656429,  0.01720939,
        1.97850843,  0.07760384]), action=5, reward=-1, next_state=array([ 0.69660506, -0.21615985, -0.05568863,  0.03337115,  0.01890603,
        1.12368565,  0.06632841]), done=False), Experience(state=array([ 0.40225293, -0.62590288,  0.00641717,  0.03109042,  0.01365697,
        1.01017061,  0.22991086]), action=9, reward=-1, next_state=array([ 0.40103111, -0.61573294,  0.15771903,  0.02247643,  0.01403393,
        1.16465187,  0.07855161]), done=False), Experience(state=array([ 0.66449056, -0.16678266,  0.1028419 ,  0.03888114,  0.01989499,
       11.1845853 ,  0.11303089]), action=7, reward=-1, next_state=array([ 0.66187301, -0.18620615,  0.11292765,  0.08083788,  0.03641301,
       10.83321097,  0.1455503 ]), done=False), Experience(state=array([ 0.48678222, -0.3738983 ,  0.12396561,  0.02988806,  0.01369735,
        1.47691569,  0.1193572 ]), action=3, reward=-1, next_state=array([ 0.48077417, -0.37336426,  0.12475777,  0.03708895,  0.02291576,
        1.83715066,  0.13798323]), done=False), Experience(state=array([ 0.66923261, -0.22194049, -0.05735742,  0.02077774,  0.01166107,
        1.11609519,  0.05453171]), action=4, reward=-1, next_state=array([ 0.60226819, -0.19395436, -0.06292603,  0.06405745,  0.04429392,
        1.70673696,  0.0591913 ]), done=False), Experience(state=array([ 0.66312925, -0.15682879,  0.11606417,  0.03452611,  0.02147604,
        4.35557329,  0.06673137]), action=7, reward=-1, next_state=array([ 0.67427779, -0.3514766 ,  0.14339156,  0.39377754,  0.33527813,
        3.63942289,  0.11129362]), done=False), Experience(state=array([ 0.57883227, -0.19431219, -0.10250656,  0.02962332,  0.01571779,
        1.9430713 ,  0.046181  ]), action=4, reward=-1, next_state=array([ 0.57924865, -0.19457956, -0.10232918,  0.01724379,  0.00953733,
        1.77286257,  0.03659154]), done=False), Experience(state=array([ 0.69083426, -0.2698591 , -0.06102727,  0.02288592,  0.01271177,
        1.94459509,  0.06441219]), action=4, reward=-1, next_state=array([ 0.62925605, -0.27338675, -0.06203939,  0.10199002,  0.05903703,
        1.4775519 ,  0.08398825]), done=False), Experience(state=array([ 0.81745294, -0.36871896,  0.0759658 ,  0.01928114,  0.01669185,
        1.08170075,  0.06445033]), action=3, reward=-1, next_state=array([ 0.81567689, -0.36804639,  0.07454202,  0.03411017,  0.01914887,
        1.70078926,  0.04173891]), done=False), Experience(state=array([ 0.64225326, -0.20764331,  0.1147702 ,  0.0335892 ,  0.01733857,
        4.92528508,  0.06053866]), action=7, reward=-1, next_state=array([ 0.61526342, -0.55836032,  0.15999107,  0.25732523,  0.13989955,
        4.98870923,  0.18090784]), done=False), Experience(state=array([ 0.55598633, -0.4567894 ,  0.03625351,  0.01982715,  0.01079616,
        7.83155681,  0.87196339]), action=7, reward=-1, next_state=array([ 5.60675263e-01, -4.65913636e-01,  4.03661329e-02,  1.82582023e-02,
        8.90106886e-03,  1.43125426e+01,  1.55216164e+00]), done=False), Experience(state=array([ 0.66598545, -0.13370907,  0.06317991,  0.0260942 ,  0.01310292,
        2.86711801,  0.11203638]), action=7, reward=-1, next_state=array([ 0.52034214, -0.47298967,  0.04107535,  0.03312297,  0.0154448 ,
       12.30961792,  1.77048051]), done=False), Experience(state=array([ 0.67103096, -0.19194337, -0.03377497,  0.02667314,  0.01780549,
        2.63941503,  0.03870297]), action=5, reward=-1, next_state=array([ 0.67219164, -0.19108967, -0.0333936 ,  0.01846058,  0.01212746,
        1.08387866,  0.03277368]), done=False), Experience(state=array([ 0.61391802, -0.18623314,  0.03690862,  0.02657952,  0.01373469,
        2.24857661,  0.02918346]), action=4, reward=-1, next_state=array([ 0.61716935, -0.19739388, -0.02408369,  0.07213685,  0.0854653 ,
        2.14354367,  0.06200553]), done=False), Experience(state=array([ 0.65232388, -0.15627932, -0.04111793,  0.02419219,  0.01368911,
        4.19629135,  0.55944318]), action=5, reward=-1, next_state=array([ 0.65663711, -0.15043354, -0.04056979,  0.032152  ,  0.01875621,
        2.56768332,  0.60673434]), done=False), Experience(state=array([ 0.6517895 , -0.18331772,  0.06380205,  0.02294873,  0.01320139,
        1.88325239,  0.12199651]), action=4, reward=-1, next_state=array([ 0.6497433 , -0.17843649, -0.06404604,  0.02158842,  0.01608826,
        5.40991496,  0.55374531]), done=False), Experience(state=array([ 0.70730961, -0.09446005, -0.0415018 ,  0.03093997,  0.0198491 ,
        1.11368848,  0.08434431]), action=5, reward=-1, next_state=array([ 0.70219557, -0.0963914 ,  0.04706773,  0.02911221,  0.0159077 ,
        1.17001361,  0.07065646]), done=False), Experience(state=array([ 0.52679363, -0.81816685,  0.03385431,  0.02985166,  0.01654498,
        2.05374696,  0.07601161]), action=9, reward=-1, next_state=array([ 0.53229192, -0.8154861 ,  0.23535133,  0.1184287 ,  0.02297539,
        1.09954605,  0.08255838]), done=False), Experience(state=array([ 0.62908312, -0.22985641,  0.11541453,  0.02987265,  0.01575309,
        1.29761423,  0.06190565]), action=4, reward=-1, next_state=array([ 0.6389783 , -0.23411382, -0.02123554,  0.06086315,  0.07601584,
        1.75872541,  0.05230121]), done=False), Experience(state=array([ 0.52674064, -0.81884624,  0.03430581,  0.03092042,  0.01796184,
        1.89933964,  0.08287199]), action=9, reward=-1, next_state=array([ 0.53254024, -0.81918824,  0.13810997,  0.05304635,  0.02546162,
        2.88282542,  0.05403272]), done=False), Experience(state=array([ 0.5410304 , -0.65232076,  0.03805799,  0.03008628,  0.01490562,
        3.3446811 ,  0.07912099]), action=9, reward=-1, next_state=array([ 0.6105409 , -0.63036007,  0.18003076,  0.07905222,  0.25759693,
        2.33839017,  0.06781006]), done=False), Experience(state=array([ 0.64903229, -0.21548513, -0.06759285,  0.03269533,  0.01768699,
        4.30866569,  0.1074283 ]), action=5, reward=-1, next_state=array([ 0.64879938, -0.21682012, -0.06822874,  0.01198716,  0.00991757,
        4.83607938,  0.08058096]), done=False), Experience(state=array([ 0.58359579, -0.20527108, -0.06180779,  0.02250715,  0.01648585,
        1.8089455 ,  0.08409439]), action=5, reward=-1, next_state=array([ 0.58614161, -0.20599314, -0.06081141,  0.0263771 ,  0.01372099,
        3.34780176,  0.03540804]), done=False), Experience(state=array([ 0.64785953, -0.12620957,  0.1165729 ,  0.02262218,  0.01450503,
        3.08465249,  0.06154734]), action=7, reward=-1, next_state=array([ 0.64286779, -0.39850389,  0.14044425,  0.75203366,  0.51172651,
        2.97550485,  0.06438485]), done=False), Experience(state=array([ 0.66324524, -0.19467604,  0.04664083,  0.03004953,  0.01489719,
        1.11878694,  0.16079381]), action=4, reward=-1, next_state=array([ 0.68837796, -0.2012768 , -0.04044964,  0.02057469,  0.01112913,
        3.04584682,  0.21595439]), done=False), Experience(state=array([ 0.7090472 , -0.28037693,  0.06440543,  0.02781474,  0.01753981,
        1.83639304,  0.061301  ]), action=4, reward=-1, next_state=array([ 0.72335033, -0.23244045, -0.04794612,  0.05892006,  0.01799527,
        3.11902679,  0.04676013]), done=False), Experience(state=array([ 0.43620221, -0.6484359 ,  0.03690222,  0.03020735,  0.01743735,
        1.69753354,  0.10327166]), action=9, reward=-1, next_state=array([ 0.43705408, -0.64023114,  0.18784643,  0.05223207,  0.02600534,
        1.4323353 ,  0.0843622 ]), done=False), Experience(state=array([ 0.64416979, -0.34920389,  0.08769654,  0.01735225,  0.00903008,
        1.6145063 ,  0.09062193]), action=7, reward=-1, next_state=array([ 0.64393087, -0.34943985,  0.08764209,  0.02543378,  0.01326649,
        1.77274086,  0.10704178]), done=False), Experience(state=array([ 0.7486049 , -0.15291312, -0.04716797,  0.02244705,  0.01803428,
        2.95422826,  0.23134795]), action=5, reward=-1, next_state=array([ 0.74847867, -0.15315655, -0.04719616,  0.02334664,  0.01605996,
        3.41891149,  0.36685593]), done=False), Experience(state=array([ 0.67238852, -0.17125062,  0.05117178,  0.02836225,  0.0139871 ,
        1.74818752,  0.04259965]), action=7, reward=-1, next_state=array([ 0.58177301, -0.63751476,  0.05978958,  0.0309932 ,  0.01495422,
        4.7621165 ,  0.4605397 ]), done=False), Experience(state=array([ 0.76138136, -0.11073171,  0.11340153,  0.03347873,  0.01462132,
        4.49776275,  0.06017332]), action=7, reward=-1, next_state=array([ 0.58443197, -0.69044602,  0.12168076,  0.02925398,  0.01533862,
        1.82248411,  0.3840322 ]), done=False), Experience(state=array([ 0.68270389, -0.17272936, -0.0653053 ,  0.03203275,  0.01575972,
        1.92367901,  0.05182946]), action=5, reward=-1, next_state=array([ 0.6844527 , -0.17649418, -0.06362618,  0.03033856,  0.01161419,
        2.0989489 ,  0.06569171]), done=False), Experience(state=array([ 0.67609997, -0.16245657, -0.02670969,  0.02927789,  0.0149119 ,
        3.85789596,  0.24511602]), action=5, reward=-1, next_state=array([ 0.68324152, -0.15515577,  0.03850013,  0.03935975,  0.02726484,
        1.47243911,  0.07490843]), done=False), Experience(state=array([ 0.59095415, -0.13266308,  0.11278831,  0.02441325,  0.01251076,
        1.86487827,  0.08963134]), action=4, reward=-1, next_state=array([ 0.59874839, -0.13543148,  0.01456565,  0.03774297,  0.0145408 ,
        8.88914579,  0.84027874]), done=False), Experience(state=array([ 0.74155612, -0.27819946,  0.02535586,  0.02869277,  0.0178476 ,
        1.39666066,  0.0538604 ]), action=5, reward=-1, next_state=array([ 0.74156044, -0.27801147,  0.02569575,  0.02372953,  0.01473016,
        1.85450866,  0.04819191]), done=False), Experience(state=array([ 0.64787551, -0.16139728,  0.11156398,  0.02427953,  0.01178948,
        3.47631331,  0.04329796]), action=7, reward=-1, next_state=array([ 0.61204996, -0.58016341,  0.17399677,  0.31732183,  0.24725771,
        2.71070127,  0.07054905]), done=False), Experience(state=array([ 0.62585456, -0.24841495, -0.05891532,  0.02226836,  0.01073494,
        3.26163025,  0.04081096]), action=5, reward=-1, next_state=array([ 0.62596647, -0.24800461, -0.05772001,  0.02219375,  0.01292146,
        3.06804825,  0.04721526]), done=False), Experience(state=array([ 0.65250367, -0.40891566,  0.12104776,  0.0248081 ,  0.01327869,
        1.68146361,  0.0834301 ]), action=7, reward=-1, next_state=array([ 0.52367548, -0.82046566,  0.23059181,  0.04387372,  0.02926986,
        1.78590296,  0.1089923 ]), done=False), Experience(state=array([ 0.69544913, -0.17845474, -0.03546365,  0.02913928,  0.01519223,
        1.45278706,  0.03798881]), action=5, reward=-1, next_state=array([ 0.70019566, -0.17959792, -0.03171708,  0.02544693,  0.01459894,
        1.19311637,  0.04097935]), done=False), Experience(state=array([ 0.81553439, -0.45215892,  0.08616937,  0.01886733,  0.01139212,
        0.91977673,  0.1856584 ]), action=3, reward=-1, next_state=array([ 0.80378785, -0.32447292,  0.0938557 ,  0.05030023,  0.02932502,
        1.76055371,  0.17279579]), done=False), Experience(state=array([ 0.72325175, -0.11284148,  0.1014702 ,  0.02014695,  0.01081119,
        1.46248508,  0.06256743]), action=4, reward=-1, next_state=array([ 0.72677588, -0.12266089,  0.02078344,  0.03868991,  0.02480553,
        2.05590756,  0.07062015]), done=False), Experience(state=array([ 0.58382125, -0.22721694, -0.03567756,  0.03420056,  0.02410974,
        3.30280901,  0.12597675]), action=5, reward=-1, next_state=array([ 0.93608882, -0.46659564,  0.06206176,  0.54059185,  0.13633904,
        6.86851918,  0.06233345]), done=False), Experience(state=array([ 7.34105908e-01, -1.27751229e-01, -1.52800870e-04,  3.22399586e-02,
        2.04883103e-02,  1.48587757e+00,  7.20351421e-02]), action=4, reward=-1, next_state=array([ 0.66792208, -0.17853525, -0.00519964,  0.10165609,  0.05239842,
        2.44242751,  0.0641575 ]), done=False), Experience(state=array([ 0.52579645, -0.81730096,  0.03363222,  0.02612207,  0.01164235,
        2.32071915,  0.0485    ]), action=9, reward=-1, next_state=array([ 0.53242803, -0.81661919,  0.13256113,  0.04418698,  0.02324392,
        1.16544915,  0.06293594]), done=False), Experience(state=array([ 0.6996138 , -0.06515738, -0.07140687,  0.02295648,  0.01860678,
        1.44730088,  0.05740954]), action=5, reward=-1, next_state=array([ 0.70404417, -0.06485221, -0.06887767,  0.02547261,  0.01641029,
        2.05563108,  0.07828164]), done=False), Experience(state=array([ 0.53056216, -0.80238229,  0.05863257,  0.02781513,  0.01290304,
        1.98180409,  0.05258728]), action=8, reward=100, next_state=array([ 0.53008108, -0.80151213,  0.05889787,  0.02550853,  0.01543204,
        2.01028339,  0.05477517]), done=True), Experience(state=array([ 0.6877249 , -0.2423795 , -0.10977785,  0.02184512,  0.01263997,
        2.38438023,  0.02992586]), action=5, reward=-1, next_state=array([ 0.68793402, -0.24077353, -0.10876926,  0.02164387,  0.01365501,
        1.10836837,  0.02133089]), done=False), Experience(state=array([ 0.72934617, -0.11206228, -0.06994628,  0.02696426,  0.01911199,
        1.76599021,  0.05398083]), action=4, reward=-1, next_state=array([ 0.73249358, -0.06331764, -0.07038486,  0.06361308,  0.02487541,
        2.6026427 ,  0.06201905]), done=False), Experience(state=array([ 0.81679786, -0.45000524,  0.08699319,  0.02353939,  0.01565193,
        2.28930324,  0.0647787 ]), action=3, reward=-1, next_state=array([ 0.75837496, -0.20295571,  0.0920962 ,  0.04251915,  0.03055457,
        3.33775015,  0.06338548]), done=False), Experience(state=array([ 0.77022169, -0.15204868, -0.03737528,  0.02503358,  0.01339024,
        1.36698506,  0.10086829]), action=3, reward=-1, next_state=array([ 0.74546981, -0.16074546,  0.12026192,  0.04649172,  0.03524491,
        1.42237554,  0.06468278]), done=False), Experience(state=array([ 0.65752102, -0.21322703, -0.00436874,  0.02953584,  0.01639364,
        1.85257916,  0.23802507]), action=5, reward=-1, next_state=array([ 0.8300213 , -0.14779132,  0.20399689,  0.3573095 ,  0.24599882,
        2.46440832,  0.09628687]), done=False), Experience(state=array([ 0.5291577 , -0.81904232,  0.22953193,  0.02089091,  0.01252247,
        5.24157687,  0.11632436]), action=8, reward=100, next_state=array([ 0.53479369, -0.81508208,  0.07721923,  0.06833728,  0.12036934,
        5.37427419,  0.10102475]), done=True), Experience(state=array([ 0.72088436, -0.12744379,  0.10446848,  0.02426239,  0.01402094,
        1.82786153,  0.04394469]), action=4, reward=-1, next_state=array([ 0.74513505, -0.11054187,  0.05099897,  0.02278205,  0.01401661,
       12.32883298,  1.00341562]), done=False), Experience(state=array([ 7.04814328e-01, -2.07513571e-01,  7.02406099e-05,  2.19710583e-02,
        8.10617644e-03,  1.58519118e+00,  6.75545242e-02]), action=4, reward=-1, next_state=array([ 7.46369062e-01, -1.80808122e-01, -1.68908138e-03,  8.05773564e-02,
        3.54972642e-02,  2.41666282e+00,  6.39648684e-02]), done=False), Experience(state=array([ 0.52336623, -0.82095453,  0.23079781,  0.04934393,  0.03539506,
        1.70569769,  0.1176274 ]), action=8, reward=100, next_state=array([ 0.52769991, -0.81906352,  0.23123562,  0.02242428,  0.01286252,
        1.95949489,  0.10171288]), done=True), Experience(state=array([ 0.63630019, -0.26428512,  0.07935527,  0.0322812 ,  0.01970155,
        2.60860048,  0.06494781]), action=4, reward=-1, next_state=array([ 0.62993791, -0.25797292, -0.03719858,  0.04451541,  0.06423994,
        2.06609719,  0.07407692]), done=False), Experience(state=array([ 0.62091355, -0.13539652,  0.03642213,  0.03149259,  0.01281296,
        1.68473564,  0.02270214]), action=4, reward=-1, next_state=array([ 0.62424239, -0.14777016, -0.02232276,  0.07115575,  0.08998581,
        2.37704702,  0.03821133]), done=False), Experience(state=array([ 0.77097143, -0.22922026, -0.10784412,  0.01717411,  0.01176005,
        1.00178501,  0.05537335]), action=4, reward=-1, next_state=array([ 0.77088448, -0.22895427, -0.10776255,  0.02697724,  0.01252682,
        1.46337835,  0.05507223]), done=False), Experience(state=array([ 7.86660071e-01, -1.61427926e-01, -4.28499478e-04,  3.19905121e-02,
        1.95909207e-02,  1.98031225e+00,  9.92895677e-02]), action=4, reward=-1, next_state=array([ 0.82208079, -0.15107143, -0.12931497,  0.03084691,  0.01879556,
        2.00775687,  0.11361294]), done=False), Experience(state=array([ 6.69183343e-01, -2.13865852e-01, -2.99067331e-03,  2.90773758e-02,
        1.73317055e-02,  3.13680129e+00,  6.37145833e-02]), action=5, reward=-1, next_state=array([ 6.69237544e-01, -2.14275416e-01, -3.03209711e-03,  3.35417202e-02,
        1.54955008e-02,  3.09963689e+00,  1.77633971e-01]), done=False), Experience(state=array([ 0.75989678, -0.15466799, -0.05530644,  0.03317618,  0.01673945,
        2.55180372,  0.10061237]), action=5, reward=-1, next_state=array([ 0.77402394, -0.1522556 , -0.03713289,  0.01935785,  0.01407064,
        1.88861443,  0.1030772 ]), done=False), Experience(state=array([ 0.52682667, -0.81928531,  0.03398992,  0.0380913 ,  0.02432199,
        1.39629189,  0.05302811]), action=9, reward=-1, next_state=array([ 0.53289488, -0.819475  ,  0.139     ,  0.04271256,  0.02913732,
        1.24031663,  0.06212416]), done=False), Experience(state=array([ 0.52931083, -0.81961245,  0.23047857,  0.02861823,  0.01322278,
        3.26336182,  0.10676341]), action=8, reward=100, next_state=array([ 0.524396  , -0.81995996,  0.18068486,  0.13309666,  0.10006956,
        3.5869727 ,  0.08678913]), done=True), Experience(state=array([ 0.71193597, -0.11440283,  0.10050166,  0.01981558,  0.01122456,
        1.29148266,  0.04818821]), action=4, reward=-1, next_state=array([ 0.70830032, -0.11703268,  0.00360212,  0.02351871,  0.01462803,
        2.93678052,  0.08045884]), done=False), Experience(state=array([ 0.7189686 , -0.14579123, -0.02184262,  0.03186497,  0.01657547,
        1.69971592,  0.05925113]), action=5, reward=-1, next_state=array([ 0.73605341, -0.14587982,  0.05239629,  0.04362361,  0.02734248,
        1.79797095,  0.05316306]), done=False), Experience(state=array([ 0.66464313, -0.16180408,  0.03422582,  0.02441595,  0.01323478,
        2.11365444,  0.0438293 ]), action=7, reward=-1, next_state=array([ 0.66205104, -0.18129602,  0.03703976,  0.42283928,  0.14730537,
        2.6857079 ,  0.04651734]), done=False), Experience(state=array([ 0.72666892, -0.1813479 ,  0.03349542,  0.03169245,  0.00994489,
        1.85935529,  0.04781801]), action=4, reward=-1, next_state=array([ 0.71575929, -0.20296327, -0.11846277,  0.03389677,  0.01987263,
        1.71753073,  0.0411656 ]), done=False), Experience(state=array([ 0.62641234, -0.23400658, -0.03850397,  0.03707227,  0.01656353,
        3.15357245,  0.12492533]), action=5, reward=-1, next_state=array([ 0.63211571, -0.22631755, -0.03527884,  0.02960093,  0.01295136,
        3.24767608,  0.06429283]), done=False), Experience(state=array([ 0.67653319, -0.16283924,  0.06267719,  0.02121494,  0.01216264,
        2.66501315,  0.13424476]), action=7, reward=-1, next_state=array([ 5.27235470e-01, -4.72739416e-01,  4.36255212e-02,  2.43381662e-02,
        1.10704887e-02,  1.38445417e+01,  1.48885283e+00]), done=False), Experience(state=array([ 0.74664643, -0.20866067,  0.03217502,  0.11157691,  0.08828195,
        2.55982045,  0.05895919]), action=7, reward=-1, next_state=array([ 0.75235796, -0.2025333 ,  0.03581562,  0.03225709,  0.01545963,
        1.96253689,  0.06060666]), done=False), Experience(state=array([ 0.67475986, -0.18567616,  0.00598361,  0.02929914,  0.01554371,
        1.1141975 ,  0.05564765]), action=4, reward=-1, next_state=array([ 0.67207949, -0.19176631, -0.11830381,  0.0714651 ,  0.03352858,
        1.66846198,  0.05605164]), done=False), Experience(state=array([ 0.67291903, -0.28977284,  0.08877021,  0.02639424,  0.00939572,
        1.60293226,  0.10468789]), action=7, reward=-1, next_state=array([ 0.67276541, -0.28944494,  0.08877042,  0.03275048,  0.01292557,
        1.20907549,  0.09924282]), done=False), Experience(state=array([ 0.63784934, -0.23583816,  0.11262919,  0.02681459,  0.01758901,
        2.74964863,  0.05579529]), action=4, reward=-1, next_state=array([ 0.63835732, -0.24175916,  0.04918184,  0.04924521,  0.07277666,
        2.0534234 ,  0.07043449]), done=False), Experience(state=array([ 0.52445437, -0.81920347,  0.03329811,  0.04908978,  0.03037774,
        6.07636455,  0.10482576]), action=9, reward=-1, next_state=array([ 0.53282298, -0.81601039,  0.13612412,  0.03235866,  0.01691514,
        2.61676403,  0.0683926 ]), done=False), Experience(state=array([ 0.71429963, -0.30713711, -0.02385621,  0.03191875,  0.01549541,
        2.30300231,  0.06513505]), action=4, reward=-1, next_state=array([ 0.72144598, -0.2768263 , -0.02505399,  0.02170802,  0.01103234,
        2.4417027 ,  0.04803216]), done=False), Experience(state=array([ 7.48404871e-01, -1.76497873e-01, -6.02783120e-04,  2.51784384e-02,
        1.49402134e-02,  1.34095372e+00,  6.73943482e-02]), action=4, reward=-1, next_state=array([ 7.92358796e-01, -1.32749152e-01, -5.73515062e-04,  5.40064107e-02,
        2.44189385e-02,  3.70345357e+00,  1.64990886e-01]), done=False), Experience(state=array([ 0.6865724 , -0.13890652,  0.05168706,  0.0559488 ,  0.0279196 ,
        2.48964922,  0.0852389 ]), action=7, reward=-1, next_state=array([ 0.65782422, -0.47223665,  0.09942231,  0.03504937,  0.02885228,
        1.46250504,  0.0982927 ]), done=False), Experience(state=array([ 0.81733195, -0.45244458,  0.08814885,  0.03546439,  0.01879283,
        4.49934057,  0.07993843]), action=3, reward=-1, next_state=array([ 0.81734241, -0.45127569,  0.089954  ,  0.03756308,  0.03140065,
        4.3944687 ,  0.08182004]), done=False), Experience(state=array([ 0.63075404, -0.28090524, -0.06068384,  0.02283057,  0.01365511,
        3.81638173,  0.02899307]), action=5, reward=-1, next_state=array([ 0.6344096 , -0.30070923, -0.06020072,  0.0585779 ,  0.03010773,
        3.0141967 ,  0.0861365 ]), done=False), Experience(state=array([ 0.80309224, -0.15021361, -0.03053453,  0.02481208,  0.01762547,
        1.71204005,  0.09082077]), action=4, reward=-1, next_state=array([ 0.80346725, -0.08302457, -0.03861625,  0.03381554,  0.02380421,
        1.43849835,  0.08974251]), done=False), Experience(state=array([ 6.74668807e-01, -4.02631653e-01,  1.62875255e-03,  2.59707744e-02,
        1.24593703e-02,  1.96098516e+00,  6.02134865e-02]), action=4, reward=-1, next_state=array([ 0.68346099, -0.28282494, -0.05997685,  0.02514728,  0.01619503,
        3.29129217,  0.04191682]), done=False), Experience(state=array([ 0.65678271, -0.17306513, -0.08206305,  0.02798721,  0.0159905 ,
        1.79889981,  0.08521856]), action=5, reward=-1, next_state=array([ 0.65329676, -0.17451813, -0.02287837,  0.06409506,  0.10468938,
        3.08389948,  0.11883334]), done=False), Experience(state=array([ 0.65747484, -0.15895845, -0.04743502,  0.03097525,  0.01725902,
        2.99010123,  0.20710107]), action=5, reward=-1, next_state=array([ 0.65675966, -0.15993119, -0.04741949,  0.02922464,  0.01431033,
        4.19136249,  0.41191413]), done=False), Experience(state=array([ 0.72774668, -0.19004069, -0.03866054,  0.0258155 ,  0.01212597,
        3.6731901 ,  0.05242696]), action=5, reward=-1, next_state=array([ 0.73651101, -0.1935861 ,  0.01658311,  0.03354198,  0.01805255,
        4.84678601,  0.05471756]), done=False), Experience(state=array([ 0.67759722, -0.15691472,  0.06463745,  0.0258894 ,  0.01572187,
        3.47743442,  0.17490402]), action=7, reward=-1, next_state=array([ 0.56117974, -0.47925208,  0.04821898,  0.02513401,  0.01590305,
        4.24506735,  0.57212363]), done=False), Experience(state=array([ 0.65536871, -0.16756606,  0.06073491,  0.0349954 ,  0.01892036,
        1.5633831 ,  0.15786118]), action=7, reward=-1, next_state=array([ 0.52909538, -0.4731468 ,  0.03869642,  0.03631348,  0.01750534,
       10.54817215,  1.11434265]), done=False), Experience(state=array([ 0.64320019, -0.13292288,  0.0878386 ,  0.03472267,  0.01606189,
        3.32161353,  0.08225679]), action=7, reward=-1, next_state=array([ 0.61539035, -0.49313047,  0.17028924,  0.25518153,  0.23407883,
        6.74988639,  0.42875715]), done=False), Experience(state=array([ 6.84022825e-01, -2.37836007e-01, -1.32490065e-03,  3.13891495e-02,
        2.07736568e-02,  2.00372877e+00,  7.70622337e-02]), action=4, reward=-1, next_state=array([ 6.25341014e-01, -1.92911047e-01,  2.42353550e-03,  6.01363297e-02,
        9.38947692e-02,  2.90039507e+00,  2.97948469e-01]), done=False), Experience(state=array([ 0.52791062, -0.82054639,  0.0353735 ,  0.02855748,  0.01569859,
        1.57567379,  0.07318065]), action=9, reward=-1, next_state=array([ 0.52978306, -0.82178635,  0.14247941,  0.03685901,  0.02795256,
        2.45313722,  0.07679931]), done=False), Experience(state=array([ 0.73043191, -0.11990546, -0.06891863,  0.04328414,  0.01707094,
        2.91230127,  0.04123377]), action=5, reward=-1, next_state=array([ 0.73147751, -0.12057198, -0.06876285,  0.02704779,  0.01620336,
        2.979196  ,  0.05254437]), done=False), Experience(state=array([ 0.60540862, -0.15459968,  0.11373907,  0.03056633,  0.01740428,
        5.93653219,  0.04927068]), action=7, reward=-1, next_state=array([ 5.63578425e-01, -6.31305148e-01,  6.16467878e-02,  2.64275035e-02,
        1.02938671e-02,  2.38734593e+01,  2.30820830e+00]), done=False), Experience(state=array([ 5.72293145e-01, -4.80946467e-01,  5.02287244e-02,  2.73426946e-02,
        1.11585932e-02,  2.01419038e+01,  1.98097659e+00]), action=7, reward=-1, next_state=array([ 5.73864643e-01, -4.81400915e-01,  5.18363433e-02,  1.92912099e-02,
        1.27434940e-02,  2.02034788e+01,  1.98952405e+00]), done=False), Experience(state=array([ 0.73937228, -0.15673163,  0.04755119,  0.03124394,  0.01399271,
        1.60234643,  0.07544941]), action=4, reward=-1, next_state=array([ 0.78939227, -0.16018192, -0.0401391 ,  0.01992299,  0.0158417 ,
        3.80141711,  0.17433103]), done=False), Experience(state=array([ 0.48818294, -0.85399031,  0.11760191,  0.02490135,  0.01589451,
        3.31685488,  0.0681932 ]), action=8, reward=100, next_state=array([ 0.53060683, -0.81828451,  0.0365525 ,  0.05093245,  0.02169879,
        2.23978601,  0.06906654]), done=True), Experience(state=array([ 0.66253675, -0.17952345,  0.10977741,  0.04024061,  0.01768253,
        3.8377058 ,  0.04931727]), action=7, reward=-1, next_state=array([ 0.62269518, -0.57855345,  0.17185744,  0.32314306,  0.23060094,
        2.87335018,  0.0534572 ]), done=False), Experience(state=array([ 0.52906582, -0.82186995,  0.03703888,  0.02648777,  0.01786255,
        3.01119294,  0.08325919]), action=9, reward=-1, next_state=array([ 0.53241799, -0.81926214,  0.19330087,  0.06142035,  0.02625314,
        1.73694598,  0.06637809]), done=False), Experience(state=array([ 0.65706428, -0.25977127,  0.03740022,  0.02458574,  0.01069163,
        2.74140408,  0.08338008]), action=4, reward=-1, next_state=array([ 0.62472818, -0.25998358, -0.03745619,  0.03013563,  0.0196254 ,
        2.74894204,  0.08689313]), done=False), Experience(state=array([ 0.52758183, -0.81874598,  0.03657941,  0.0337672 ,  0.01667071,
        2.11268326,  0.0919347 ]), action=9, reward=-1, next_state=array([ 0.52007567, -0.82621237,  0.08191991,  0.07089762,  0.16043812,
        1.7527829 ,  0.06905931]), done=False), Experience(state=array([ 0.6884211 , -0.04611616, -0.03855001,  0.01856202,  0.01091793,
        2.02972062,  0.08705045]), action=5, reward=-1, next_state=array([ 0.68434719, -0.04196864, -0.03895641,  0.01426871,  0.0107641 ,
        2.79946658,  0.05809057]), done=False), Experience(state=array([ 0.7033641 , -0.16226765,  0.05090605,  0.03712256,  0.01747227,
        3.02857738,  0.04957321]), action=7, reward=-1, next_state=array([ 0.62829706, -0.58142271,  0.15835958,  0.03345088,  0.01214706,
        3.56146078,  0.44168868]), done=False), Experience(state=array([ 0.66198057, -0.31010081,  0.12863549,  0.02626347,  0.01337799,
        2.37016666,  0.09368988]), action=7, reward=-1, next_state=array([ 0.66179959, -0.31102876,  0.12807428,  0.02997144,  0.01172256,
        2.86827688,  0.10017069]), done=False), Experience(state=array([ 0.64868199, -0.14686286,  0.15236604,  0.03637004,  0.01701102,
        2.4479931 ,  0.05499193]), action=7, reward=-1, next_state=array([ 0.65020888, -0.3404714 ,  0.17441405,  0.74879813,  0.41608186,
        6.35214022,  0.48510066]), done=False), Experience(state=array([ 0.64440973, -0.20134825,  0.04769579,  0.02148264,  0.01565452,
        2.66083935,  0.05389832]), action=7, reward=-1, next_state=array([ 0.57792544, -0.63730982,  0.06205905,  0.02812124,  0.01505878,
        4.49937713,  0.41428588]), done=False), Experience(state=array([ 0.6583342 , -0.18747577,  0.06804503,  0.02350173,  0.01309922,
        1.50654464,  0.14407805]), action=4, reward=-1, next_state=array([ 0.65900669, -0.18516452, -0.06197339,  0.02222484,  0.01437308,
        4.24014122,  0.40096267]), done=False), Experience(state=array([ 0.6373604 , -0.67920328,  0.21634971,  0.02611878,  0.0141357 ,
        1.88013367,  0.06238726]), action=9, reward=-1, next_state=array([ 0.63765726, -0.67789196,  0.21186899,  0.02015697,  0.01336857,
        1.24985506,  0.05248622]), done=False), Experience(state=array([ 0.68905393, -0.27017637, -0.07208901,  0.03484596,  0.01837902,
        2.38305153,  0.05532828]), action=5, reward=-1, next_state=array([ 0.69661055, -0.270834  , -0.05579186,  0.67834781,  0.05230679,
        1.46132067,  0.0982255 ]), done=False), Experience(state=array([ 6.46996333e-01, -1.23703042e-01, -8.50131029e-02,  1.67002898e-02,
        1.23396243e-02,  1.65326383e+01,  7.11023944e-01]), action=5, reward=-1, next_state=array([ 6.46996333e-01, -1.23703042e-01, -8.50131029e-02,  1.67002898e-02,
        1.23396243e-02,  1.65326383e+01,  7.11023944e-01]), done=False), Experience(state=array([ 0.71729507, -0.20658697, -0.10919087,  0.02741182,  0.01444397,
        0.83176496,  0.03117219]), action=5, reward=-1, next_state=array([ 0.71783224, -0.20664066, -0.1087567 ,  0.02744872,  0.01960622,
        0.89942702,  0.02969084]), done=False), Experience(state=array([ 0.68183894, -0.25700833,  0.17491832,  0.03352856,  0.01896778,
        2.98945006,  0.05672812]), action=7, reward=-1, next_state=array([ 0.68053776, -0.25462813,  0.1719093 ,  0.0806213 ,  0.05461136,
        3.43223798,  0.07463902]), done=False), Experience(state=array([ 0.5272806 , -0.81684415,  0.03362785,  0.02998074,  0.02009291,
        1.32583304,  0.06992686]), action=9, reward=-1, next_state=array([ 0.53090282, -0.82104562,  0.13719586,  0.03040764,  0.01695886,
        1.95304086,  0.05627068]), done=False), Experience(state=array([ 0.64765316, -0.31069493,  0.09059369,  0.02911108,  0.01827656,
        1.75540314,  0.05179761]), action=7, reward=-1, next_state=array([ 0.64079735, -0.5006221 ,  0.15943459,  0.2336281 ,  0.27148047,
        3.04596687,  0.0738369 ]), done=False), Experience(state=array([ 0.68866171, -0.25494955, -0.01543073,  0.03051512,  0.01624404,
        1.6319971 ,  0.04939421]), action=4, reward=-1, next_state=array([ 0.66970796, -0.26357397, -0.03713094,  0.10494598,  0.02693911,
        2.28826542,  0.06468424]), done=False), Experience(state=array([ 0.43324471, -0.64826588,  0.07948224,  0.03166052,  0.01030103,
        3.16800418,  0.11111464]), action=9, reward=-1, next_state=array([ 0.43877367, -0.64428341,  0.23053582,  0.03665957,  0.0222576 ,
        2.06146196,  0.09106599]), done=False), Experience(state=array([ 0.52473362, -0.82178429,  0.23113592,  0.03247667,  0.02381387,
        3.32819486,  0.11098138]), action=8, reward=100, next_state=array([ 0.52622964, -0.81894795,  0.22019748,  0.03724405,  0.08024978,
        1.45834904,  0.11088855]), done=True), Experience(state=array([ 0.63873332, -0.16429688, -0.08555152,  0.0210529 ,  0.00810324,
        1.55146406,  0.08638352]), action=5, reward=-1, next_state=array([ 0.64077887, -0.16912471, -0.05378174,  0.04522033,  0.08571789,
        3.05893518,  0.12392205]), done=False), Experience(state=array([ 0.52415836, -0.82172481,  0.2313309 ,  0.03478168,  0.01986689,
        3.74081061,  0.09343944]), action=8, reward=100, next_state=array([ 0.52804058, -0.81921992,  0.23157474,  0.02763466,  0.01842574,
        2.98712354,  0.10934672]), done=True), Experience(state=array([ 0.66875373, -0.1944029 ,  0.11407368,  0.03335444,  0.0200343 ,
        7.24183127,  0.03207949]), action=7, reward=-1, next_state=array([ 0.64143944, -0.54181534,  0.17014833,  0.30019971,  0.3196553 ,
        4.86616837,  0.12782306]), done=False), Experience(state=array([ 0.73839938, -0.16201255, -0.00294767,  0.03817309,  0.02004729,
        1.39431465,  0.06882572]), action=5, reward=-1, next_state=array([ 7.41642526e-01, -1.62303707e-01,  9.96718849e-04,  3.87546762e-02,
        2.43440850e-02,  1.10589063e+00,  5.57087914e-02]), done=False), Experience(state=array([ 0.61222086, -0.08833433, -0.06669872,  0.02791222,  0.01858864,
        2.39050867,  0.06467462]), action=3, reward=-1, next_state=array([ 0.6126105 , -0.08849011, -0.0666697 ,  0.02234648,  0.01249687,
        2.13691174,  0.05631629]), done=False), Experience(state=array([ 0.62775161, -0.13495756,  0.15245156,  0.04034858,  0.01766615,
        2.70326943,  0.04257576]), action=7, reward=-1, next_state=array([ 0.63115193, -0.35325649,  0.18504797,  0.19059292,  0.13202822,
        8.73538997,  0.49444268]), done=False), Experience(state=array([ 0.66826146, -0.31507851,  0.05766549,  0.0262214 ,  0.01714021,
        4.56887295,  0.06154556]), action=3, reward=-1, next_state=array([ 0.6696927 , -0.31554993,  0.05771859,  0.02370791,  0.01425892,
        2.30497169,  0.0900535 ]), done=False), Experience(state=array([ 0.64831134, -0.17552951, -0.08759942,  0.02589009,  0.01532369,
        1.98670004,  0.11668382]), action=5, reward=-1, next_state=array([ 0.65142931, -0.18099129, -0.06049604,  0.07008851,  0.08829551,
        0.95949039,  0.0812573 ]), done=False), Experience(state=array([ 0.71635634, -0.09327927, -0.03923682,  0.02382147,  0.01722098,
        3.18282442,  0.0854515 ]), action=5, reward=-1, next_state=array([ 0.71838199, -0.08667206,  0.04195413,  0.02306538,  0.01276364,
        3.24969069,  0.06783171]), done=False), Experience(state=array([ 0.625921  , -0.23884105, -0.03734113,  0.02886203,  0.01583489,
        2.57510826,  0.12533469]), action=5, reward=-1, next_state=array([ 0.64191893, -0.20404877,  0.06820743,  0.04177322,  0.02367605,
        2.67181769,  0.05983223]), done=False), Experience(state=array([ 0.67310003, -0.314504  ,  0.03995908,  0.02854743,  0.0191501 ,
        1.44471342,  0.08014174]), action=4, reward=-1, next_state=array([ 0.67898757, -0.31284345, -0.01055846,  0.11597073,  0.13322085,
        2.29635153,  0.06500138]), done=False), Experience(state=array([ 0.43902175, -0.65053744,  0.03669155,  0.04533783,  0.02689353,
        1.67451293,  0.08890215]), action=9, reward=-1, next_state=array([ 0.43721719, -0.642811  ,  0.1868269 ,  0.05211776,  0.02087835,
        2.20194524,  0.07472079]), done=False), Experience(state=array([ 0.66593312, -0.11808561,  0.06621559,  0.03066221,  0.01905893,
        2.14828397,  0.11409301]), action=4, reward=-1, next_state=array([ 0.6641178 , -0.11763158, -0.06282848,  0.04184731,  0.02162429,
        4.9137621 ,  0.44162248]), done=False), Experience(state=array([ 0.66122078, -0.1726354 ,  0.11146522,  0.02110777,  0.00991681,
        3.85973518,  0.04636836]), action=7, reward=-1, next_state=array([ 0.61081391, -0.63744147,  0.17848186,  0.33841026,  0.30147593,
        1.93100583,  0.05603376]), done=False), Experience(state=array([ 0.52336504, -0.82174185,  0.23164799,  0.05383058,  0.02268391,
        2.33327255,  0.08808179]), action=8, reward=100, next_state=array([ 0.53413854, -0.81976933,  0.0875548 ,  0.14440656,  0.09774315,
        3.71851565,  0.11304757]), done=True), Experience(state=array([ 0.62131052, -0.17752966,  0.11809091,  0.02322714,  0.01317303,
        2.40477316,  0.02492592]), action=7, reward=-1, next_state=array([ 0.57005652, -0.63142675,  0.06499293,  0.03245009,  0.01533673,
        6.14595816,  0.65081256]), done=False), Experience(state=array([ 0.70797409, -0.08254666, -0.03576198,  0.02244849,  0.01747028,
        2.83760511,  0.11225397]), action=5, reward=-1, next_state=array([ 0.7055462 , -0.02348679,  0.04555987,  0.02974024,  0.01504729,
        2.97303101,  0.09796624]), done=False), Experience(state=array([ 0.66050459, -0.17303137,  0.11218985,  0.01947241,  0.00980576,
        2.87718616,  0.14252029]), action=7, reward=-1, next_state=array([ 0.53815385, -0.46582038,  0.04660172,  0.03718807,  0.02170728,
        8.9222651 ,  1.14924059]), done=False), Experience(state=array([ 0.68646059, -0.06901206,  0.00700681,  0.02499192,  0.01558411,
        2.89689443,  0.06370715]), action=4, reward=-1, next_state=array([ 0.68685343, -0.06858588,  0.00727008,  0.0201653 ,  0.00927211,
        2.50086922,  0.07338544]), done=False), Experience(state=array([ 0.74299357, -0.14568072,  0.05108905,  0.03120354,  0.01884118,
        1.71667501,  0.05315907]), action=4, reward=-1, next_state=array([ 0.78787142, -0.15075409, -0.04266438,  0.02978747,  0.01457936,
        9.77794639,  0.50836222]), done=False), Experience(state=array([ 0.66137643, -0.29373823, -0.10551015,  0.03538729,  0.0248505 ,
        2.06301268,  0.07077199]), action=5, reward=-1, next_state=array([ 0.66124403, -0.2933342 , -0.10463357,  0.02413851,  0.01370365,
        2.07626542,  0.0570847 ]), done=False), Experience(state=array([ 0.68004067, -0.1386205 ,  0.11415296,  0.02069513,  0.01108669,
        8.48939143,  0.06484088]), action=7, reward=-1, next_state=array([ 0.58101588, -0.73223769,  0.14876303,  0.02678606,  0.01617721,
        1.27972768,  0.05830636]), done=False), Experience(state=array([ 0.6867056 , -0.13460203,  0.10938954,  0.02406855,  0.01863123,
        2.60040249,  0.04585756]), action=4, reward=-1, next_state=array([ 0.69555302, -0.14696632, -0.04478044,  0.02161729,  0.01588082,
        2.66825039,  0.05551316]), done=False), Experience(state=array([ 0.52475332, -0.41375593,  0.18248215,  0.02673711,  0.01488692,
        1.06282774,  0.15677189]), action=3, reward=-1, next_state=array([ 0.5158729 , -0.40817028,  0.18093987,  0.05832935,  0.04202536,
        1.03723431,  0.12753986]), done=False), Experience(state=array([ 0.72058423, -0.12718085,  0.10411049,  0.02760168,  0.01316527,
        2.03954153,  0.0772745 ]), action=4, reward=-1, next_state=array([ 0.7152131 , -0.12807513,  0.01118636,  0.02680351,  0.01329916,
        2.34092128,  0.08447203]), done=False), Experience(state=array([ 0.70094561, -0.18663489, -0.07380651,  0.0238848 ,  0.01465986,
        2.00367955,  0.04578164]), action=5, reward=-1, next_state=array([ 0.7014485 , -0.18533127, -0.0728467 ,  0.03108989,  0.01920737,
        2.59056006,  0.07736915]), done=False), Experience(state=array([ 0.64468613, -0.15134256,  0.06869941,  0.02268783,  0.01210915,
        1.86820428,  0.08803223]), action=7, reward=-1, next_state=array([ 0.63473944, -0.16346274,  0.06427824,  0.11606652,  0.12864608,
        2.60976905,  0.08314434]), done=False), Experience(state=array([ 0.70532057, -0.11856264,  0.09811725,  0.02373444,  0.01211955,
        2.12391049,  0.05935974]), action=4, reward=-1, next_state=array([ 0.70495808, -0.11917158,  0.01411477,  0.06563596,  0.03359382,
        3.37645479,  0.05344793]), done=False), Experience(state=array([ 0.70655045, -0.08360641, -0.0398915 ,  0.03000975,  0.01868382,
        2.21875467,  0.07361795]), action=5, reward=-1, next_state=array([ 0.69774724, -0.06840555,  0.05448811,  0.02510839,  0.01480347,
        1.63774125,  0.08227009]), done=False), Experience(state=array([ 0.63776328, -0.17841662,  0.08466005,  0.02515365,  0.01298619,
        1.90479215,  0.06871418]), action=7, reward=-1, next_state=array([ 0.63861967, -0.28420354,  0.09070677,  0.02907501,  0.0170896 ,
        9.30950636,  0.4038787 ]), done=False), Experience(state=array([ 0.63889286, -0.6761224 ,  0.20313596,  0.02192697,  0.01116039,
        3.02103734,  0.03392265]), action=9, reward=-1, next_state=array([ 0.6371003 , -0.67486614,  0.19889257,  0.0252255 ,  0.01411023,
        3.0701083 ,  0.03952134]), done=False), Experience(state=array([ 0.53557277, -0.4086777 ,  0.12898565,  0.03457817,  0.01541603,
        1.39888684,  0.08713202]), action=3, reward=-1, next_state=array([ 0.53137791, -0.41215061,  0.12609421,  0.07339099,  0.02881014,
        2.46470148,  0.04454133]), done=False), Experience(state=array([ 0.68853652, -0.14641143, -0.02170167,  0.01523702,  0.0101313 ,
        1.39149947,  0.04614107]), action=5, reward=-1, next_state=array([ 0.70685104, -0.15548382,  0.03930406,  0.04898344,  0.03531162,
        1.46762023,  0.09471001]), done=False), Experience(state=array([ 0.66782495, -0.1667908 ,  0.1415182 ,  0.03190295,  0.01547703,
        4.91831488,  0.17970548]), action=7, reward=-1, next_state=array([ 5.34459275e-01, -4.67262296e-01,  4.67145434e-02,  2.02104506e-02,
        1.19404361e-02,  1.42207169e+01,  1.51168186e+00]), done=False), Experience(state=array([ 0.67710299, -0.18577865, -0.12118911,  0.01886966,  0.01517956,
        1.86525465,  0.0928566 ]), action=5, reward=-1, next_state=array([ 6.80287218e-01, -1.98098421e-01, -1.84213621e-04,  2.84271678e-02,
        1.56319012e-02,  1.73089076e+00,  9.83625592e-02]), done=False), Experience(state=array([ 0.73283615, -0.13506489,  0.10309292,  0.02377904,  0.01463957,
        3.69697312,  0.05801605]), action=4, reward=-1, next_state=array([ 7.32814957e-01, -1.42139710e-01, -1.05982806e-03,  3.47276062e-02,
        2.30422759e-02,  3.51188975e+00,  5.83494325e-02]), done=False), Experience(state=array([ 0.45184448, -0.8799908 ,  0.19839438,  0.03275784,  0.01784443,
        2.63046507,  0.05583329]), action=8, reward=100, next_state=array([ 0.46627077, -0.84439412,  0.18562852,  0.08824187,  0.08786258,
        2.88207116,  0.04747776]), done=True), Experience(state=array([ 0.73265334, -0.15026462,  0.05274776,  0.03337581,  0.01814228,
        1.78548839,  0.06830912]), action=4, reward=-1, next_state=array([ 0.7817902 , -0.15431826, -0.04309544,  0.04462403,  0.02142064,
        4.75540984,  0.38115421]), done=False), Experience(state=array([ 0.76247916, -0.28348709, -0.10303187,  0.03066104,  0.02181973,
        1.67109794,  0.05034648]), action=4, reward=-1, next_state=array([ 0.72376333, -0.24709117, -0.10269676,  0.04391845,  0.02390501,
        1.67391912,  0.03801223]), done=False), Experience(state=array([ 0.67158153, -0.30897368,  0.02653702,  0.02748457,  0.01314513,
        2.04698159,  0.06120697]), action=4, reward=-1, next_state=array([ 0.67217281, -0.26198397, -0.03172531,  0.04309174,  0.02490368,
        1.94556617,  0.05761033]), done=False), Experience(state=array([ 0.68716922, -0.17868469,  0.11088359,  0.03880452,  0.02274601,
        2.38193983,  0.05670184]), action=4, reward=-1, next_state=array([ 0.66833585, -0.18934673,  0.03603635,  0.03940194,  0.02285261,
        3.14270645,  0.06919874]), done=False), Experience(state=array([ 0.71711859, -0.12693621,  0.1042881 ,  0.02633867,  0.01713543,
        1.60646876,  0.07744106]), action=4, reward=-1, next_state=array([ 0.71287237, -0.13134906,  0.02473852,  0.0341355 ,  0.021875  ,
        1.89596469,  0.07427324]), done=False), Experience(state=array([ 0.75258447, -0.13018644,  0.04771081,  0.02639552,  0.01619192,
        2.59339608,  0.08005445]), action=4, reward=-1, next_state=array([ 0.76151292, -0.1344152 , -0.04510417,  0.03320725,  0.01861638,
       12.71213016,  1.28975386]), done=False), Experience(state=array([ 0.70501332, -0.14253621, -0.02219769,  0.02881297,  0.01702017,
        3.04566772,  0.2042644 ]), action=5, reward=-1, next_state=array([ 0.71897888, -0.15104883,  0.04195158,  0.05862757,  0.03814964,
        1.53196215,  0.07798931]), done=False), Experience(state=array([ 0.75796142, -0.26720724, -0.10331085,  0.02195044,  0.01203395,
        1.26359512,  0.03773191]), action=4, reward=-1, next_state=array([ 0.7077947 , -0.25472356, -0.1035366 ,  0.07370604,  0.03565786,
        1.56581948,  0.06235851]), done=False), Experience(state=array([ 0.63085835, -0.1963394 ,  0.04395432,  0.02536504,  0.01327831,
        2.94098978,  0.07699793]), action=7, reward=-1, next_state=array([ 0.63763024, -0.41700752,  0.07393926,  0.03621113,  0.0230364 ,
        3.38157878,  0.06224676]), done=False), Experience(state=array([ 0.63414124, -0.19072928,  0.04372133,  0.0373567 ,  0.01752114,
        1.24451026,  0.06252532]), action=7, reward=-1, next_state=array([ 0.63144931, -0.40767293,  0.06585675,  0.09631538,  0.05325673,
        1.46513996,  0.06338847]), done=False), Experience(state=array([ 0.78739846, -0.12467717,  0.11428549,  0.02699248,  0.02365015,
        2.91251575,  0.16745424]), action=7, reward=-1, next_state=array([ 0.65243315, -0.4258658 ,  0.05995052,  0.02755125,  0.01220069,
        3.98011783,  0.28337799]), done=False), Experience(state=array([ 0.529101  , -0.81944659,  0.23093017,  0.02281806,  0.01355479,
        4.59935007,  0.08109753]), action=8, reward=100, next_state=array([ 0.52853587, -0.81593   ,  0.06316558,  0.0599584 ,  0.11265028,
        4.98759019,  0.08613867]), done=True), Experience(state=array([ 0.52973189, -0.82532173,  0.04418526,  0.04360272,  0.02644877,
        3.24829201,  0.13065135]), action=9, reward=-1, next_state=array([ 0.52805698, -0.8218182 ,  0.13840819,  0.04215634,  0.02501096,
        2.14343108,  0.13902872]), done=False), Experience(state=array([ 0.65899708, -0.14570574,  0.11280194,  0.03564353,  0.01805259,
        2.9715315 ,  0.05674286]), action=7, reward=-1, next_state=array([ 0.62022954, -0.57182621,  0.1742253 ,  0.26933856,  0.23765692,
        3.87661721,  0.1266251 ]), done=False), Experience(state=array([ 0.69244084, -0.16324009,  0.18454078,  0.03005588,  0.01426826,
        2.13206158,  0.05471702]), action=7, reward=-1, next_state=array([ 0.69340882, -0.2665915 ,  0.18451568,  0.09407438,  0.10868829,
        2.90115284,  0.06163905]), done=False), Experience(state=array([ 0.81588987, -0.45071172,  0.08610538,  0.01848119,  0.01225517,
        2.26630181,  0.08290541]), action=3, reward=-1, next_state=array([ 0.81597888, -0.45179888,  0.08731859,  0.03202957,  0.01692312,
        2.87758947,  0.07924007]), done=False), Experience(state=array([ 0.52826525, -0.81945549,  0.22850373,  0.05019941,  0.02603594,
       10.63650662,  0.17810648]), action=8, reward=100, next_state=array([ 0.52775085, -0.81519519,  0.11245547,  0.05126645,  0.11796064,
       11.32572205,  0.29915183]), done=True), Experience(state=array([ 0.67169233, -0.31243148,  0.03904352,  0.02339494,  0.0111649 ,
        2.22774147,  0.07782907]), action=4, reward=-1, next_state=array([ 0.68125102, -0.31386652, -0.02311924,  0.09209764,  0.18435446,
        2.6662299 ,  0.06710145]), done=False), Experience(state=array([ 0.66770749, -0.25305228,  0.05998144,  0.02588066,  0.01846362,
        2.42735947,  0.05972555]), action=4, reward=-1, next_state=array([ 0.66052843, -0.16041135, -0.0104297 ,  0.02748084,  0.01399467,
        1.72167042,  0.07695161]), done=False), Experience(state=array([ 0.64052018, -0.19853912,  0.04134993,  0.02742186,  0.01190669,
        1.40813888,  0.04912464]), action=4, reward=-1, next_state=array([ 0.63929656, -0.21367193, -0.11109799,  0.03850252,  0.02041046,
        2.1055389 ,  0.04285605]), done=False), Experience(state=array([ 0.63747985, -0.18898455,  0.07850231,  0.03254143,  0.01613239,
        1.83243407,  0.07935284]), action=4, reward=-1, next_state=array([ 0.63961602, -0.19036469,  0.01496905,  0.06613358,  0.08422556,
        2.1252474 ,  0.09627631]), done=False), Experience(state=array([ 0.72146295, -0.12826123,  0.05072703,  0.02767689,  0.01661382,
        2.3287799 ,  0.0739597 ]), action=4, reward=-1, next_state=array([ 0.78285285, -0.16954346, -0.0578927 ,  0.02817813,  0.01623866,
        4.97551383,  0.59017051]), done=False), Experience(state=array([ 0.6568851 , -0.16568793, -0.06503435,  0.02866648,  0.01503095,
        1.43192785,  0.04427007]), action=5, reward=-1, next_state=array([ 0.65887853, -0.1654774 , -0.06334417,  0.02975071,  0.0162651 ,
        1.091413  ,  0.05571173]), done=False), Experience(state=array([ 0.66082234, -0.36258536,  0.15364522,  0.03005569,  0.01549481,
        3.4098177 ,  0.0492726 ]), action=7, reward=-1, next_state=array([ 0.66045655, -0.36179157,  0.15305598,  0.01232069,  0.0142618 ,
        2.94811409,  0.04987649]), done=False), Experience(state=array([ 0.52714737, -0.81783026,  0.03387076,  0.02439224,  0.0131566 ,
        1.73243591,  0.06285091]), action=9, reward=-1, next_state=array([ 0.53034766, -0.82007108,  0.13911894,  0.03271702,  0.01820958,
        1.45152587,  0.06311263]), done=False), Experience(state=array([ 0.6571176 , -0.1890713 ,  0.1409759 ,  0.02447802,  0.0159555 ,
        1.51358596,  0.03881882]), action=7, reward=-1, next_state=array([ 0.65599256, -0.26362354,  0.14255253,  0.07227599,  0.20564641,
        2.70548945,  0.05467025]), done=False), Experience(state=array([ 0.81587772, -0.45106731,  0.08541861,  0.01962285,  0.01068208,
        1.50850733,  0.07495222]), action=3, reward=-1, next_state=array([ 0.78964312, -0.23053259,  0.09946026,  0.06256512,  0.03276162,
        3.84320956,  0.26087608]), done=False), Experience(state=array([ 0.6307269 , -0.23282575,  0.11556039,  0.0328687 ,  0.01467352,
        1.61646396,  0.04481774]), action=4, reward=-1, next_state=array([ 0.63198051, -0.23685965,  0.0800238 ,  0.0717395 ,  0.10183063,
        1.29732146,  0.05774688]), done=False), Experience(state=array([ 0.66816581, -0.4825068 ,  0.11617135,  0.02416203,  0.01188478,
        3.43781929,  0.1047935 ]), action=7, reward=-1, next_state=array([ 0.65092357, -0.6248187 ,  0.16832063,  0.1657476 ,  0.11105902,
        3.94372489,  0.12707678]), done=False), Experience(state=array([ 0.65999356, -0.18448205,  0.05091072,  0.02800541,  0.01423002,
        2.51819092,  0.04022355]), action=7, reward=-1, next_state=array([ 0.58147101, -0.63808832,  0.06303482,  0.03420999,  0.01613955,
        6.37543624,  0.4183639 ]), done=False), Experience(state=array([ 0.52684582, -0.81908231,  0.03444149,  0.04075317,  0.02062939,
        2.58145408,  0.13651273]), action=9, reward=-1, next_state=array([ 0.53302045, -0.81798352,  0.13654571,  0.02957394,  0.01371332,
        2.82879029,  0.13775673]), done=False), Experience(state=array([ 0.62679879, -0.13933791, -0.11760635,  0.01643536,  0.01131068,
        1.60554046,  0.07843976]), action=4, reward=-1, next_state=array([ 0.62804972, -0.14022548, -0.11729201,  0.02607634,  0.0133622 ,
        1.60206441,  0.09745475]), done=False), Experience(state=array([ 0.68059832, -0.13452803, -0.11594577,  0.02375222,  0.01351869,
        2.32602093,  0.03456237]), action=5, reward=-1, next_state=array([ 0.68361553, -0.1344592 , -0.11494041,  0.0199085 ,  0.01418903,
        2.92881876,  0.03850592]), done=False), Experience(state=array([ 0.70045064, -0.28077045,  0.04342664,  0.02552738,  0.00972138,
        1.0613988 ,  0.07942413]), action=4, reward=-1, next_state=array([ 0.70355951, -0.29152952,  0.04250426,  0.01544388,  0.00880869,
        1.15032471,  0.0606666 ]), done=False), Experience(state=array([ 0.62182082, -0.18918954, -0.11906187,  0.02834502,  0.01282823,
        2.57973269,  0.03867519]), action=5, reward=-1, next_state=array([ 0.62331778, -0.18643391, -0.11778924,  0.03369435,  0.01390715,
        2.96236471,  0.02395091]), done=False), Experience(state=array([ 0.62987214, -0.23135439,  0.11602745,  0.03446688,  0.01576707,
        2.49144711,  0.05811863]), action=4, reward=-1, next_state=array([ 0.64534141, -0.23512234, -0.03497505,  0.04376185,  0.02453582,
        2.80257117,  0.05727802]), done=False), Experience(state=array([ 0.81761592, -0.45086328,  0.08812475,  0.02756793,  0.01757917,
       11.87621262,  0.1018581 ]), action=3, reward=-1, next_state=array([ 0.81758606, -0.4509742 ,  0.0879613 ,  0.02393919,  0.01553183,
       11.85175647,  0.11019529]), done=False), Experience(state=array([ 0.52272812, -0.81655589,  0.03487815,  0.03955809,  0.03362551,
        9.49057141,  0.22807931]), action=9, reward=-1, next_state=array([ 0.52921053, -0.81835082,  0.13369778,  0.03169333,  0.01454306,
        2.66056782,  0.05684768]), done=False), Experience(state=array([ 0.52800981, -0.81911829,  0.03617996,  0.03086986,  0.02170369,
        1.1245606 ,  0.07138515]), action=9, reward=-1, next_state=array([ 0.53762001, -0.81482243,  0.24263261,  0.04421598,  0.03068375,
        1.32326154,  0.06644306]), done=False), Experience(state=array([ 0.57683545, -0.26241621,  0.11134302,  0.02899682,  0.01175372,
        2.69350282,  0.07655213]), action=4, reward=-1, next_state=array([ 0.57173522, -0.26350594,  0.10529512,  0.08242549,  0.03314751,
        2.31498708,  0.05891057]), done=False), Experience(state=array([ 0.62946345, -0.30482762,  0.04638342,  0.0343059 ,  0.02230066,
        1.90319092,  0.05483488]), action=4, reward=-1, next_state=array([ 0.6297431 , -0.30508806,  0.046488  ,  0.02862605,  0.01727382,
        2.08041563,  0.03492879]), done=False), Experience(state=array([ 0.66745984, -0.17896032, -0.08469535,  0.03087742,  0.0136372 ,
        2.70508086,  0.14712446]), action=5, reward=-1, next_state=array([ 0.67111613, -0.17289934,  0.01815354,  0.06113157,  0.0836186 ,
        2.52961876,  0.1637253 ]), done=False), Experience(state=array([ 0.65788357, -0.34952591, -0.03561816,  0.03491315,  0.01730392,
        4.04944786,  0.04874925]), action=4, reward=-1, next_state=array([ 0.66667175, -0.35174605, -0.04585547,  0.04136597,  0.025627  ,
        3.21531515,  0.05083089]), done=False), Experience(state=array([ 0.72486368, -0.14343074,  0.04816965,  0.04172219,  0.01855496,
        2.12294117,  0.08613596]), action=4, reward=-1, next_state=array([ 0.78694531, -0.13004172, -0.0438276 ,  0.02906204,  0.01473018,
        5.38736384,  0.30487697]), done=False), Experience(state=array([ 0.65664398, -0.16876982,  0.1118127 ,  0.03173395,  0.01635244,
        3.48391543,  0.05841822]), action=7, reward=-1, next_state=array([ 0.62983593, -0.52402993,  0.16663048,  0.34480821,  0.28026734,
        6.45502474,  0.10687213]), done=False), Experience(state=array([ 0.62377816, -0.16746296,  0.11430959,  0.04519231,  0.01715898,
        3.17157031,  0.03793048]), action=7, reward=-1, next_state=array([ 0.57170994, -0.63146794,  0.06231278,  0.05115522,  0.02220092,
        6.48901009,  0.53146024]), done=False), Experience(state=array([ 0.65670081, -0.23943826, -0.02204615,  0.02908114,  0.01708609,
        2.98202325,  0.08046906]), action=5, reward=-1, next_state=array([ 0.65699648, -0.23973276, -0.02191431,  0.01464773,  0.00873155,
        3.62482855,  0.07397446]), done=False), Experience(state=array([ 0.6486226 , -0.19024035, -0.04618991,  0.03632035,  0.01470735,
        2.95983176,  0.36751817]), action=5, reward=-1, next_state=array([ 0.62571906, -0.1940268 ,  0.08465569,  0.11164438,  0.10535123,
       13.38844893,  0.11286868]), done=False), Experience(state=array([ 0.7142603 , -0.22219638, -0.10768422,  0.02594473,  0.01939397,
        1.95348685,  0.05685211]), action=4, reward=-1, next_state=array([ 0.71415989, -0.22230592, -0.10761495,  0.0265199 ,  0.01660415,
        1.3457399 ,  0.05442473]), done=False), Experience(state=array([ 0.43898429, -0.64993105,  0.03523205,  0.02290854,  0.01062858,
        1.40344122,  0.09240636]), action=9, reward=-1, next_state=array([ 0.43924497, -0.64182193,  0.18578889,  0.05447391,  0.02096642,
        1.96548174,  0.10387243]), done=False), Experience(state=array([ 0.65073197, -0.25218323,  0.07226505,  0.0332642 ,  0.01849274,
        2.18012643,  0.07442055]), action=4, reward=-1, next_state=array([ 0.6382279 , -0.23302683, -0.11225202,  0.04730684,  0.0254435 ,
        2.01994542,  0.08872936]), done=False), Experience(state=array([ 0.6611729 , -0.22498959,  0.04293237,  0.09022559,  0.05375367,
        3.85171604,  0.06824678]), action=7, reward=-1, next_state=array([ 0.66011842, -0.22392834,  0.04675667,  0.05150369,  0.02839616,
        8.21707321,  0.2140107 ]), done=False), Experience(state=array([ 0.67612706, -0.2184674 , -0.06469588,  0.02100426,  0.01098645,
        1.14940382,  0.04266155]), action=4, reward=-1, next_state=array([ 0.68672667, -0.20876033, -0.0599474 ,  0.09794927,  0.07147254,
        1.6044563 ,  0.05116131]), done=False), Experience(state=array([ 0.68391051, -0.13873344, -0.06305561,  0.0267452 ,  0.01343679,
        1.65273586,  0.0672019 ]), action=4, reward=-1, next_state=array([ 0.64472654, -0.09507821, -0.06171623,  0.06518126,  0.02875242,
        1.6959125 ,  0.07018515]), done=False), Experience(state=array([ 0.65591533, -0.2204219 ,  0.11579172,  0.0285322 ,  0.01387063,
        1.97843836,  0.06517162]), action=7, reward=-1, next_state=array([ 0.65912744, -0.40982278,  0.1428068 ,  0.32224096,  0.13553665,
        2.04060543,  0.0436043 ]), done=False), Experience(state=array([ 0.65873434, -0.20137675,  0.04773047,  0.02206823,  0.01375981,
        3.76018639,  0.05276248]), action=7, reward=-1, next_state=array([ 0.58249068, -0.63859768,  0.0628764 ,  0.03117439,  0.01252374,
        4.51448859,  0.3590416 ]), done=False), Experience(state=array([ 0.6915801 , -0.16593443,  0.10637951,  0.03237646,  0.01516884,
        6.02716805,  0.14430631]), action=7, reward=-1, next_state=array([ 0.57140905, -0.4722541 ,  0.05174631,  0.03373258,  0.01982742,
        7.59432021,  0.46651666]), done=False), Experience(state=array([ 0.6945831 , -0.06313577,  0.04326031,  0.01504457,  0.01086431,
        1.46521067,  0.06480726]), action=7, reward=-1, next_state=array([ 0.70568064, -0.22135841,  0.06644008,  0.02354167,  0.01431007,
        3.08111609,  0.07126338]), done=False), Experience(state=array([ 0.76072612, -0.23680498, -0.02981964,  0.03423469,  0.0148597 ,
        1.29511416,  0.09490001]), action=4, reward=-1, next_state=array([ 0.77904945, -0.15385506, -0.03298004,  0.04122403,  0.03253007,
        2.62713688,  0.0983363 ]), done=False), Experience(state=array([ 0.74031152, -0.13631479,  0.04808398,  0.04034538,  0.02652267,
        2.55376638,  0.05945311]), action=4, reward=-1, next_state=array([ 0.75743284, -0.14640111, -0.04524807,  0.02963262,  0.01794068,
       10.03241581,  1.27246225]), done=False), Experience(state=array([ 0.71119685, -0.16109105, -0.07219469,  0.01970716,  0.01350792,
        2.96898937,  0.09455255]), action=5, reward=-1, next_state=array([ 0.71571664, -0.17124969, -0.01302773,  0.13081018,  0.12668353,
        2.14606926,  0.06977046]), done=False), Experience(state=array([ 0.7068271 , -0.10152905, -0.03930453,  0.03007591,  0.02229928,
        2.09838093,  0.07596763]), action=5, reward=-1, next_state=array([ 0.70007671, -0.09573286,  0.05299267,  0.02704687,  0.01789752,
        1.7586179 ,  0.09189465]), done=False), Experience(state=array([ 0.65498903, -0.23223033,  0.11196875,  0.02814658,  0.01530026,
        1.48772639,  0.04829871]), action=4, reward=-1, next_state=array([ 0.65887424, -0.23407978,  0.02568491,  0.0661702 ,  0.07232007,
        1.49685169,  0.05899521]), done=False), Experience(state=array([ 0.7303352 , -0.18158363,  0.10134275,  0.03142283,  0.01656476,
        1.5193207 ,  0.0615192 ]), action=4, reward=-1, next_state=array([ 0.76303214, -0.19384051,  0.04168893,  0.02824981,  0.01725408,
        2.26709471,  0.36434394]), done=False), Experience(state=array([ 0.62707952, -0.21842232, -0.04176622,  0.03588267,  0.01572283,
        3.37676257,  0.24108428]), action=5, reward=-1, next_state=array([ 0.612301  , -0.21024962, -0.01944992,  0.09860153,  0.09185902,
        7.42952825,  0.08143559]), done=False), Experience(state=array([ 0.64045661, -0.15907721, -0.08489267,  0.01828401,  0.01001392,
        1.66138199,  0.07115662]), action=5, reward=-1, next_state=array([ 0.64824674, -0.16332671,  0.06271131,  0.06334218,  0.056846  ,
        2.10840022,  0.11146853]), done=False), Experience(state=array([ 0.70508612, -0.08539514,  0.04193368,  0.03136196,  0.01688694,
        2.29819007,  0.06700945]), action=7, reward=-1, next_state=array([ 0.71468744, -0.22316454,  0.05676256,  0.03536947,  0.02250114,
        2.40687176,  0.07040455]), done=False), Experience(state=array([ 0.61925776, -0.2490275 ,  0.11230913,  0.03038071,  0.015761  ,
        2.41147222,  0.05774929]), action=4, reward=-1, next_state=array([ 0.63373964, -0.25747666, -0.0224325 ,  0.0494273 ,  0.07204373,
        1.5440021 ,  0.03718873]), done=False), Experience(state=array([ 0.73543076, -0.40755354, -0.01106233,  0.0193375 ,  0.01504494,
        2.20953233,  0.05391055]), action=4, reward=-1, next_state=array([ 0.7353796 , -0.40725751, -0.01142476,  0.01984435,  0.0117587 ,
        1.48009755,  0.04762776]), done=False), Experience(state=array([ 0.65729068, -0.15584166,  0.14683169,  0.01540645,  0.00912462,
        3.94144997,  0.07055432]), action=7, reward=-1, next_state=array([ 0.64310076, -0.30868365,  0.16360905,  0.39256791,  0.27000182,
        8.27104523,  0.52850411]), done=False), Experience(state=array([ 0.63724597, -0.23739885,  0.11178815,  0.02970381,  0.01554173,
        2.37727015,  0.05406903]), action=4, reward=-1, next_state=array([ 0.6399084 , -0.24406134,  0.03785147,  0.05581812,  0.09034258,
        1.6982823 ,  0.06092842]), done=False), Experience(state=array([ 0.67835629, -0.02499581,  0.04131748,  0.03615186,  0.01859524,
        2.07630714,  0.06071994]), action=7, reward=-1, next_state=array([ 0.66892242, -0.21359575,  0.05240859,  0.06656892,  0.02990799,
        1.47333308,  0.07944436]), done=False), Experience(state=array([ 0.44098462, -0.88504447,  0.14200107,  0.01752065,  0.01261607,
        4.31427709,  0.05781422]), action=8, reward=100, next_state=array([ 0.47126077, -0.82368968,  0.13311829,  0.1453911 ,  0.10291198,
        3.558063  ,  0.04713542]), done=True), Experience(state=array([ 0.49429934, -0.39043353,  0.13510108,  0.02386673,  0.01380047,
        0.61230152,  0.11921317]), action=3, reward=-1, next_state=array([ 0.49433189, -0.39076134,  0.13525002,  0.02907463,  0.01318192,
        1.55244569,  0.11847766]), done=False), Experience(state=array([ 0.64175656, -0.13022645,  0.06190995,  0.03745512,  0.01913653,
        4.17701258,  0.1747909 ]), action=7, reward=-1, next_state=array([ 0.5352643 , -0.47464692,  0.04035664,  0.02790462,  0.0167735 ,
        7.68193394,  0.63496626]), done=False), Experience(state=array([ 0.68984015, -0.20934063, -0.04952606,  0.02203289,  0.01139658,
        2.54061614,  0.26452588]), action=5, reward=-1, next_state=array([ 0.6893594 , -0.20831636, -0.0493678 ,  0.0252974 ,  0.01802571,
        5.51523836,  0.47109526]), done=False), Experience(state=array([ 0.65081606, -0.17412861,  0.06638306,  0.02987503,  0.01522174,
        1.53419634,  0.10518905]), action=4, reward=-1, next_state=array([ 0.64763883, -0.1752357 , -0.06341738,  0.02951904,  0.01794366,
        5.94513261,  0.54460164]), done=False), Experience(state=array([ 0.674502  , -0.23946127,  0.13440143,  0.03186948,  0.01597809,
       11.28572873,  0.31629609]), action=3, reward=-1, next_state=array([ 0.67716293, -0.23028218,  0.17065852,  0.0308797 ,  0.01570819,
       11.15556092,  0.24235927]), done=False), Experience(state=array([ 0.65915822, -0.14535452,  0.04888068,  0.026583  ,  0.01759741,
        3.31813918,  0.15044424]), action=7, reward=-1, next_state=array([ 0.59269886, -0.64078945,  0.12491931,  0.03301238,  0.01651499,
        5.99718809,  0.55084471]), done=False), Experience(state=array([ 0.60129095, -0.21741648, -0.0586002 ,  0.02502627,  0.01339672,
        2.84639456,  0.14410489]), action=5, reward=-1, next_state=array([ 0.60533749, -0.2309576 , -0.04524276,  0.14663977,  0.05960452,
        3.38015845,  0.07784992]), done=False), Experience(state=array([ 0.69626271, -0.29360207, -0.07896754,  0.02360557,  0.01285225,
        2.06106909,  0.09120603]), action=5, reward=-1, next_state=array([ 0.71735212, -0.30926759,  0.04636069,  0.04607243,  0.07164511,
        5.84631708,  0.12726939]), done=False), Experience(state=array([ 0.63066999, -0.23058676,  0.1161751 ,  0.02717777,  0.01441679,
        1.30958872,  0.05509646]), action=4, reward=-1, next_state=array([ 0.63014927, -0.23303542,  0.05710242,  0.06546598,  0.074336  ,
        1.91759504,  0.04682959]), done=False), Experience(state=array([ 0.81566122, -0.45000939,  0.08588259,  0.02725364,  0.0152266 ,
        1.96209136,  0.08940423]), action=3, reward=-1, next_state=array([ 0.81653234, -0.45076934,  0.08712524,  0.02603116,  0.01703945,
        2.26060733,  0.09041692]), done=False), Experience(state=array([ 0.70908601, -0.09429118, -0.03871366,  0.02967212,  0.01789208,
        2.06486832,  0.0802039 ]), action=5, reward=-1, next_state=array([ 0.70570654, -0.08243204,  0.04235678,  0.02856657,  0.0190214 ,
        1.93263877,  0.04310607]), done=False), Experience(state=array([ 0.63671347, -0.15200271, -0.08509202,  0.01958161,  0.01303464,
        1.1577254 ,  0.11086495]), action=5, reward=-1, next_state=array([ 0.6367291 , -0.17236954, -0.05118359,  0.07555225,  0.12522033,
        2.04915336,  0.17778   ]), done=False), Experience(state=array([ 0.68797047, -0.14627885,  0.1060525 ,  0.03255901,  0.01808834,
        5.30765668,  0.16431645]), action=7, reward=-1, next_state=array([ 0.56538165, -0.47209782,  0.05234524,  0.02668578,  0.01554164,
        7.54857535,  0.56844633]), done=False), Experience(state=array([ 0.52609927, -0.82218172,  0.23182886,  0.03709413,  0.01701712,
        3.08198761,  0.09948598]), action=8, reward=100, next_state=array([ 0.527823  , -0.8130547 ,  0.05502961,  0.13677132,  0.1322589 ,
        1.81814518,  0.08874778]), done=True), Experience(state=array([ 0.66892111, -0.14558277, -0.04164881,  0.01761802,  0.01190646,
        3.0926279 ,  0.0287855 ]), action=4, reward=-1, next_state=array([ 0.65954561, -0.23085145, -0.11962071,  0.01815485,  0.01191995,
        6.73614634,  0.24493348]), done=False), Experience(state=array([ 0.65824431, -0.20722406,  0.05823812,  0.02591108,  0.01272359,
        1.55641965,  0.13428985]), action=7, reward=-1, next_state=array([ 5.33897582e-01, -4.71921098e-01,  4.54293971e-02,  1.28005135e-02,
        8.79222314e-03,  1.35743102e+01,  1.23477087e+00]), done=False), Experience(state=array([ 0.75515685, -0.13694363,  0.05332132,  0.03566209,  0.01754806,
        1.81525498,  0.06064228]), action=4, reward=-1, next_state=array([ 0.76713418, -0.15086276, -0.04423894,  0.02724882,  0.01670293,
        9.71186464,  1.01118652]), done=False), Experience(state=array([ 0.6710254 , -0.16176734,  0.14176936,  0.03311355,  0.01485956,
        1.11330588,  0.11469899]), action=4, reward=-1, next_state=array([ 0.66877884, -0.16337447, -0.01478417,  0.01971997,  0.01212412,
        3.25040805,  0.25779859]), done=False), Experience(state=array([ 0.72777768, -0.08497952, -0.03959675,  0.03452434,  0.0223239 ,
        1.46570325,  0.048537  ]), action=5, reward=-1, next_state=array([ 0.73202442, -0.10024065,  0.04485236,  0.02769613,  0.01398081,
        2.53908988,  0.05331427]), done=False), Experience(state=array([ 0.64455781, -0.24384205, -0.10216933,  0.0305425 ,  0.01697071,
        1.58319245,  0.0349657 ]), action=4, reward=-1, next_state=array([ 0.64453912, -0.24362263, -0.10220217,  0.03046673,  0.01491326,
        2.04049456,  0.04560857]), done=False), Experience(state=array([ 0.64082923, -0.16774947, -0.08484911,  0.02828908,  0.01530851,
        2.23124127,  0.10274882]), action=5, reward=-1, next_state=array([ 0.63882084, -0.17033655, -0.07091641,  0.06245045,  0.06510979,
        2.87109235,  0.11039643]), done=False), Experience(state=array([ 0.52627883, -0.81743293,  0.23169121,  0.03146096,  0.01958571,
        2.22576538,  0.09750458]), action=8, reward=100, next_state=array([ 0.52820619, -0.81776011,  0.23243131,  0.02209424,  0.01036407,
        2.89658971,  0.09417864]), done=True), Experience(state=array([ 0.52725964, -0.81641381,  0.13149168,  0.02667925,  0.02106427,
        1.98605689,  0.20544559]), action=8, reward=100, next_state=array([ 0.53838622, -0.82132912,  0.06613406,  0.01953798,  0.01228377,
        4.73991602,  0.38211012]), done=True), Experience(state=array([ 0.66141199, -0.27316816,  0.04178753,  0.03475871,  0.01679746,
        1.12520426,  0.04907962]), action=4, reward=-1, next_state=array([ 0.65840662, -0.27407769, -0.11307003,  0.04690537,  0.02450017,
        1.23453555,  0.06737593]), done=False), Experience(state=array([ 0.6809388 , -0.15326863, -0.09909671,  0.02524924,  0.01546472,
        2.55256772,  0.11070505]), action=5, reward=-1, next_state=array([ 0.68069247, -0.15090731, -0.03769285,  0.03685743,  0.02960065,
        1.69705963,  0.05661965]), done=False), Experience(state=array([ 0.53856167, -0.66436395,  0.12701185,  0.03008926,  0.0171668 ,
        3.58487649,  0.09276894]), action=8, reward=100, next_state=array([ 0.53440768, -0.65935869,  0.03295969,  0.03259125,  0.01922143,
        7.21145124,  0.50442211]), done=True), Experience(state=array([ 0.81664563, -0.45103711,  0.08635352,  0.03382472,  0.02136785,
        0.98197715,  0.08623094]), action=3, reward=-1, next_state=array([ 0.7954219 , -0.26591766,  0.09168547,  0.08654212,  0.05673076,
        1.832888  ,  0.09208783]), done=False), Experience(state=array([ 0.81666146, -0.44988807,  0.08700675,  0.02859463,  0.01633632,
        1.48473505,  0.0676374 ]), action=3, reward=-1, next_state=array([ 0.75961473, -0.23656571,  0.08961083,  0.03920056,  0.02398434,
        1.71081508,  0.0700033 ]), done=False), Experience(state=array([ 0.64727777, -0.21768305,  0.03810042,  0.02161429,  0.01098724,
        1.15371595,  0.05218232]), action=4, reward=-1, next_state=array([ 0.64538892, -0.24077712, -0.09685435,  0.08269738,  0.09584075,
        1.48577059,  0.04931044]), done=False), Experience(state=array([ 0.68112617, -0.01645081,  0.04085328,  0.02983173,  0.01770414,
        1.87222694,  0.04962032]), action=7, reward=-1, next_state=array([ 0.66950613, -0.22194167,  0.04680056,  0.05287138,  0.04362247,
        1.0753597 ,  0.06096124]), done=False), Experience(state=array([ 0.66367206, -0.18344936, -0.08544999,  0.01700391,  0.01302517,
        1.8971244 ,  0.18062718]), action=5, reward=-1, next_state=array([ 0.66535377, -0.19581897, -0.02320183,  0.04356825,  0.076762  ,
        2.62544756,  0.14050784]), done=False), Experience(state=array([ 0.64468345, -0.22946988,  0.11605001,  0.02371729,  0.01000303,
        2.11262581,  0.06075363]), action=4, reward=-1, next_state=array([ 0.64821349, -0.22894949,  0.0207198 ,  0.0636617 ,  0.07951038,
        3.29130717,  0.06537168]), done=False), Experience(state=array([ 0.64007659, -0.43301995,  0.17085602,  0.02612124,  0.01603135,
        3.57216354,  0.07258737]), action=7, reward=-1, next_state=array([ 0.62111557, -0.59419991,  0.18920751,  0.13211453,  0.08538663,
        4.14616939,  0.08508451]), done=False), Experience(state=array([ 0.48836101, -0.86790905,  0.14287931,  0.82256335,  0.45877059,
        2.64056945,  0.07646098]), action=8, reward=100, next_state=array([ 4.21390798e-01, -8.95695449e-01,  9.27289102e-02,  2.18249337e-02,
        1.50070893e-02,  2.13823200e+01,  2.82839017e+00]), done=True), Experience(state=array([ 0.5273015 , -0.81864165,  0.23206449,  0.0322621 ,  0.01724241,
        2.13338436,  0.12825501]), action=8, reward=100, next_state=array([ 0.53138382, -0.81676149,  0.23287067,  0.03569997,  0.02604547,
        2.18065834,  0.11932284]), done=True), Experience(state=array([ 0.64371148, -0.23996107,  0.0911249 ,  0.02528582,  0.01453494,
        1.46283525,  0.08684161]), action=4, reward=-1, next_state=array([ 0.62885649, -0.22926214, -0.10360425,  0.03042967,  0.01343851,
        3.62375148,  0.07673427]), done=False), Experience(state=array([ 0.65801067, -0.26521234,  0.08049821,  0.02051521,  0.01194511,
        1.3652778 ,  0.06759869]), action=4, reward=-1, next_state=array([ 0.65513045, -0.265933  ,  0.00836436,  0.08011588,  0.07112308,
        1.2930951 ,  0.09444368]), done=False), Experience(state=array([ 0.63645068, -0.14160238,  0.0873585 ,  0.04921249,  0.02451893,
        3.08601265,  0.07531584]), action=7, reward=-1, next_state=array([ 0.62982252, -0.42331063,  0.16032045,  0.29092377,  0.25640036,
       12.28569562,  0.60729967]), done=False), Experience(state=array([ 0.67052195, -0.04106421,  0.10807817,  0.03821208,  0.02081021,
        3.35482145,  0.06934365]), action=4, reward=-1, next_state=array([ 0.67194671, -0.04101383,  0.10952479,  0.02711785,  0.01620732,
        2.91686232,  0.06100161]), done=False), Experience(state=array([ 0.6729747 , -0.1625774 ,  0.05777007,  0.0330026 ,  0.01534173,
        1.67993719,  0.11091208]), action=7, reward=-1, next_state=array([ 0.65824253, -0.40417058,  0.09077651,  0.05181785,  0.02431975,
        1.63023245,  0.06905789]), done=False), Experience(state=array([ 0.81613884, -0.44880414,  0.08539838,  0.0224012 ,  0.01912855,
        1.89979591,  0.08221509]), action=3, reward=-1, next_state=array([ 0.76384999, -0.18107993,  0.096293  ,  0.08930455,  0.04729736,
        3.26195128,  0.05254455]), done=False), Experience(state=array([ 0.66048116, -0.1627227 , -0.09364567,  0.04113874,  0.01460109,
       10.7829128 ,  0.78180479]), action=5, reward=-1, next_state=array([ 0.64712149, -0.18371719, -0.09517269,  0.01889101,  0.00966585,
        4.7508106 ,  0.3259582 ]), done=False), Experience(state=array([ 0.81338056, -0.11618788,  0.18658295,  0.12359971,  0.07963679,
        3.644867  ,  0.07794188]), action=7, reward=-1, next_state=array([ 0.79931585, -0.16879551,  0.17903833,  0.02688678,  0.0124542 ,
        3.05502949,  0.07667149]), done=False), Experience(state=array([ 0.66421035, -0.18250023, -0.08627569,  0.03447477,  0.01801719,
        1.72023903,  0.14630122]), action=5, reward=-1, next_state=array([ 0.66303636, -0.18928887, -0.06690512,  0.04558265,  0.07846111,
        2.80869474,  0.12509138]), done=False), Experience(state=array([ 0.54246006, -0.30394448, -0.06184515,  0.03261295,  0.01275408,
        2.61749038,  0.08528661]), action=5, reward=-1, next_state=array([ 0.54789376, -0.30514545, -0.05818505,  0.38956425,  0.03876136,
        2.31323363,  0.06695784]), done=False), Experience(state=array([ 5.92462494e-01, -1.48608831e-01, -1.40819632e-03,  1.27448054e-02,
        8.91029028e-03,  3.30964159e+00,  1.51211452e-01]), action=5, reward=-1, next_state=array([ 5.94178687e-01, -1.48206390e-01,  4.74902443e-04,  4.02074891e-02,
        2.12382360e-02,  2.55431074e+00,  1.62649574e-01]), done=False), Experience(state=array([ 0.61467093, -0.26549217, -0.11388337,  0.03999434,  0.02311926,
        2.5493678 ,  0.06898366]), action=5, reward=-1, next_state=array([ 0.61407518, -0.26635697, -0.11441914,  0.0243421 ,  0.01745259,
        1.73399752,  0.08454857]), done=False), Experience(state=array([ 0.63236026, -0.21669984, -0.02045094,  0.03954943,  0.02165041,
        4.67111186,  0.22576403]), action=5, reward=-1, next_state=array([ 0.63222403, -0.21717609, -0.02034609,  0.0272763 ,  0.01738776,
        4.42209771,  0.19513441]), done=False), Experience(state=array([ 0.52850505, -0.81894091,  0.23235517,  0.02888366,  0.01495518,
        2.06117311,  0.09866458]), action=8, reward=100, next_state=array([ 0.52811137, -0.81536913,  0.18602227,  0.03967764,  0.02022788,
        1.28166813,  0.09567909]), done=True), Experience(state=array([ 0.71435632, -0.16979055,  0.10254757,  0.02047364,  0.010686  ,
        1.68002367,  0.05268266]), action=4, reward=-1, next_state=array([ 0.74842072, -0.18182088,  0.03775253,  0.02993683,  0.0104721 ,
        2.52079381,  0.20733949]), done=False), Experience(state=array([ 0.70351948, -0.16692755, -0.05255269,  0.01790586,  0.01033146,
        3.26791699,  0.1239688 ]), action=5, reward=-1, next_state=array([ 0.70831468, -0.16565284, -0.0490597 ,  0.02413704,  0.01098577,
        3.36673369,  0.10940031]), done=False), Experience(state=array([ 0.64943226, -0.184323  , -0.08466878,  0.02198117,  0.01141555,
        3.19182801,  0.14375244]), action=5, reward=-1, next_state=array([ 0.66661395, -0.18434559,  0.06874866,  0.04008812,  0.02768099,
        4.17579331,  0.13014527]), done=False), Experience(state=array([ 0.74866237, -0.16317706,  0.00203085,  0.02852398,  0.01904358,
        1.53001805,  0.08136826]), action=4, reward=-1, next_state=array([ 0.66705357, -0.17281484, -0.00418145,  0.06642173,  0.05314307,
        2.28474184,  0.08174535]), done=False), Experience(state=array([ 0.69645493, -0.2827059 ,  0.00601685,  0.02226267,  0.01264943,
        2.25776594,  0.06065331]), action=4, reward=-1, next_state=array([ 0.70327636, -0.29939089, -0.10408035,  0.02737075,  0.01739934,
        1.2536748 ,  0.07817278]), done=False), Experience(state=array([ 0.70693095, -0.08151144, -0.03979387,  0.04457247,  0.02321395,
        2.149446  ,  0.0762262 ]), action=5, reward=-1, next_state=array([ 0.697655  , -0.08470124,  0.06060278,  0.02612295,  0.01143459,
        1.2878399 ,  0.05025155]), done=False), Experience(state=array([ 0.61798524, -0.18874363,  0.11096359,  0.04980447,  0.02647212,
        6.85603172,  0.02927999]), action=7, reward=-1, next_state=array([ 0.57289675, -0.63186759,  0.06170237,  0.03964787,  0.01459053,
        7.65022847,  0.5569237 ]), done=False), Experience(state=array([ 0.67574156, -0.22375413,  0.16129108,  0.03166425,  0.0140938 ,
        3.86464813,  0.05496507]), action=7, reward=-1, next_state=array([ 0.67345158, -0.29890561,  0.16054761,  0.08457043,  0.18702157,
        2.26579213,  0.06800375]), done=False), Experience(state=array([ 0.67617516, -0.03241403,  0.04117595,  0.02406431,  0.01402501,
        2.6041941 ,  0.04780471]), action=7, reward=-1, next_state=array([ 0.67513117, -0.2218644 ,  0.05505872,  0.07220067,  0.04192657,
        2.34879585,  0.05107111]), done=False), Experience(state=array([ 0.52901308, -0.82221987,  0.03693325,  0.0258981 ,  0.01419909,
        2.78251175,  0.09065457]), action=9, reward=-1, next_state=array([ 0.52632309, -0.81869501,  0.0339931 ,  0.03358879,  0.01589574,
        2.84794784,  0.08669528]), done=False), Experience(state=array([ 0.64204093, -0.17630017, -0.11779838,  0.03617671,  0.01462598,
        3.79225558,  0.04229621]), action=5, reward=-1, next_state=array([ 0.64468668, -0.13380095, -0.0248433 ,  0.06989802,  0.07399609,
        2.41443417,  0.05914685]), done=False), Experience(state=array([ 0.6571443 , -0.16454463, -0.09047056,  0.02954894,  0.0135366 ,
        1.78679896,  0.08508509]), action=5, reward=-1, next_state=array([ 0.66018622, -0.1615221 , -0.01802413,  0.0514368 ,  0.02691018,
        1.52580304,  0.08858396]), done=False), Experience(state=array([ 0.64541249, -0.35662426,  0.06437094,  0.03086816,  0.01453516,
        1.26070152,  0.0795315 ]), action=7, reward=-1, next_state=array([ 0.64554927, -0.35705713,  0.064572  ,  0.02492176,  0.01404171,
        2.04155759,  0.06766187]), done=False), Experience(state=array([ 0.65092904, -0.21200139,  0.07795891,  0.01753574,  0.00930335,
        1.11203701,  0.07474704]), action=4, reward=-1, next_state=array([ 0.65552039, -0.22140866, -0.00847058,  0.04923841,  0.16722516,
        0.92710358,  0.0686649 ]), done=False), Experience(state=array([ 0.70645497, -0.13018408, -0.0182283 ,  0.02898801,  0.01779548,
        3.0480861 ,  0.15684632]), action=5, reward=-1, next_state=array([ 0.71124711, -0.14494387,  0.01789499,  0.04455235,  0.02431905,
        2.25870007,  0.08200092]), done=False), Experience(state=array([ 0.68249311, -0.18480427, -0.11321459,  0.03796554,  0.01972673,
        2.36055074,  0.0784512 ]), action=3, reward=-1, next_state=array([ 0.68193434, -0.1844834 , -0.11330425,  0.03311651,  0.01843697,
        1.84841412,  0.06816134]), done=False), Experience(state=array([ 0.52998144, -0.82030846,  0.03520472,  0.02847937,  0.01679845,
        2.30678495,  0.07437139]), action=8, reward=100, next_state=array([ 0.53074211, -0.82043156,  0.03531756,  0.02414397,  0.01451628,
        3.15464734,  0.07166034]), done=True), Experience(state=array([ 0.71558464, -0.18528022, -0.11930029,  0.0213798 ,  0.01686399,
        2.46059548,  0.09610134]), action=3, reward=-1, next_state=array([ 0.71532406, -0.18513715, -0.11939999,  0.0171709 ,  0.01618746,
        1.52288202,  0.09879911]), done=False), Experience(state=array([ 0.66368781, -0.24587027,  0.07955144,  0.0279851 ,  0.01141724,
        2.01045844,  0.06489984]), action=4, reward=-1, next_state=array([ 0.66350065, -0.24853822,  0.01639108,  0.09184847,  0.08261434,
        2.17237953,  0.07105354]), done=False), Experience(state=array([ 0.5268983 , -0.82129608,  0.23276088,  0.05090218,  0.03111619,
        2.21534255,  0.09155571]), action=8, reward=100, next_state=array([ 0.52774956, -0.81328338,  0.22727423,  0.16830604,  0.09040754,
        5.77472849,  0.29288246]), done=True), Experience(state=array([ 0.52769618, -0.81967048,  0.23304527,  0.01797799,  0.01228178,
        3.40960664,  0.07868258]), action=8, reward=100, next_state=array([ 0.51479668, -0.82987564,  0.04704662,  0.14575378,  0.14949986,
        4.75476148,  0.37248632]), done=True), Experience(state=array([ 0.66075979, -0.20029265, -0.04286605,  0.04254747,  0.01826886,
        3.87617448,  0.33463449]), action=5, reward=-1, next_state=array([ 0.63919486, -0.19716677,  0.10275363,  0.04548385,  0.02114815,
        8.51357949,  0.12524313]), done=False), Experience(state=array([ 0.46957465, -0.85491044,  0.07087089,  0.0175013 ,  0.01015566,
        3.81475326,  0.07491064]), action=8, reward=100, next_state=array([ 0.53418169, -0.82024852,  0.03785804,  0.01766719,  0.01390218,
        3.37657208,  0.0645707 ]), done=True), Experience(state=array([ 0.70677993, -0.16232656, -0.02132475,  0.02312661,  0.01265211,
        4.94832728,  0.249522  ]), action=5, reward=-1, next_state=array([ 0.71347715, -0.16160968,  0.03024374,  0.05124171,  0.03187426,
        1.2531637 ,  0.0748832 ]), done=False), Experience(state=array([ 0.53750734, -0.65566   ,  0.03523209,  0.02360254,  0.01376961,
        2.26256839,  0.0873842 ]), action=9, reward=-1, next_state=array([ 0.54419316, -0.66469789,  0.18422522,  0.03161602,  0.01852863,
        1.63744581,  0.08893283]), done=False), Experience(state=array([ 0.62886865, -0.18805798, -0.08796487,  0.03219896,  0.01190203,
        1.8727704 ,  0.07485769]), action=5, reward=-1, next_state=array([ 0.62806985, -0.19103624, -0.04747589,  0.10462628,  0.08532326,
        3.8849292 ,  0.12069208]), done=False), Experience(state=array([ 0.59376742, -0.16687539,  0.10824613,  0.02343753,  0.01362578,
        1.7609383 ,  0.12339051]), action=4, reward=-1, next_state=array([ 0.58604836, -0.16660768, -0.04750821,  0.02911355,  0.01943497,
        1.43373148,  0.13868429]), done=False), Experience(state=array([ 0.53282229, -0.66049321,  0.02136569,  0.04112806,  0.01917215,
        3.89453923,  0.12101809]), action=9, reward=-1, next_state=array([ 0.53736505, -0.67259033,  0.17389056,  0.03222015,  0.01966096,
        2.38797848,  0.14524833]), done=False), Experience(state=array([ 0.63151149, -0.24301394,  0.11266071,  0.02965001,  0.01878684,
        2.32201426,  0.06480751]), action=4, reward=-1, next_state=array([ 0.63006467, -0.25911712,  0.04785454,  0.04696039,  0.07494103,
        1.54318266,  0.06727769]), done=False), Experience(state=array([ 0.52545866, -0.82116359,  0.23160681,  0.02681494,  0.01679123,
        1.11503018,  0.12407824]), action=8, reward=100, next_state=array([ 0.52838581, -0.81892056,  0.22473059,  0.06801821,  0.05806532,
        1.91987333,  0.10908188]), done=True), Experience(state=array([ 0.41707147, -0.90502503,  0.03494861,  0.03206679,  0.0216053 ,
        3.55485678,  0.08504379]), action=8, reward=100, next_state=array([ 0.4706416 , -0.86469369,  0.04048523,  0.283134  ,  0.24485197,
        3.17164395,  0.09511949]), done=True), Experience(state=array([ 0.52868807, -0.81855002,  0.22962769,  0.03274419,  0.02088258,
       12.02439941,  0.20128835]), action=8, reward=100, next_state=array([ 0.52207333, -0.81803178,  0.03153695,  0.02835139,  0.01600022,
       14.32956107,  0.17288436]), done=True), Experience(state=array([ 0.6648086 , -0.2495047 ,  0.13137651,  0.02274093,  0.01443648,
        2.03251271,  0.04521913]), action=7, reward=-1, next_state=array([ 0.6563766 , -0.28631168,  0.12788078,  0.11692013,  0.19547885,
        1.25649972,  0.06972545]), done=False), Experience(state=array([ 0.69623257, -0.18547893, -0.10871721,  0.02987563,  0.01938589,
        2.52226835,  0.02533522]), action=5, reward=-1, next_state=array([ 0.69669862, -0.18522861, -0.10777881,  0.0308917 ,  0.01979046,
        1.33492334,  0.04044861]), done=False), Experience(state=array([ 0.62476159, -0.25909656, -0.03773617,  0.03553755,  0.01819801,
        2.60491342,  0.13426526]), action=5, reward=-1, next_state=array([ 0.60946139, -0.24736805,  0.06826548,  0.08082808,  0.08310503,
        9.69069453,  0.07121581]), done=False), Experience(state=array([ 0.67921042, -0.23672647, -0.07222504,  0.02220388,  0.00997026,
        2.66392328,  0.04483877]), action=4, reward=-1, next_state=array([ 0.71409916, -0.18595997, -0.07259084,  0.09528154,  0.03743959,
        2.22849074,  0.07790831]), done=False), Experience(state=array([ 0.63143446, -0.18158199,  0.11163226,  0.0295879 ,  0.0181197 ,
        1.52787778,  0.04579218]), action=4, reward=-1, next_state=array([ 0.62906859, -0.18290032,  0.1106272 ,  0.01841196,  0.00925118,
        1.4886637 ,  0.06624743]), done=False), Experience(state=array([ 0.68073073, -0.17294663,  0.06135127,  0.03587028,  0.01621414,
        1.97455089,  0.16212725]), action=4, reward=-1, next_state=array([ 0.66492366, -0.16092329, -0.09297342,  0.04328829,  0.02122125,
        1.85718658,  0.14818759]), done=False), Experience(state=array([ 0.70341192, -0.31060818,  0.0894683 ,  0.02265376,  0.01370226,
        0.99316492,  0.06468818]), action=3, reward=-1, next_state=array([ 0.70998208, -0.24488022,  0.08938293,  0.29729175,  0.18086385,
        1.66629159,  0.08389238]), done=False), Experience(state=array([ 0.71324714, -0.17279968, -0.02087177,  0.02201042,  0.01308856,
        2.43349163,  0.08670172]), action=5, reward=-1, next_state=array([ 0.71793738, -0.17790202,  0.02676541,  0.03710112,  0.02428013,
        1.44965964,  0.05897771]), done=False), Experience(state=array([ 0.64321279, -0.18401176,  0.10479541,  0.02546537,  0.014044  ,
       12.21948934,  0.10338603]), action=7, reward=-1, next_state=array([ 0.66721638, -0.40796472,  0.18433125,  0.53827426,  0.22779577,
       16.13974274,  0.85979383]), done=False), Experience(state=array([ 0.68240135, -0.32967334, -0.05572484,  0.02329215,  0.01373571,
        2.46132064,  0.07287858]), action=3, reward=-1, next_state=array([ 0.68224951, -0.33004499, -0.05476569,  0.02448446,  0.0130857 ,
        2.8402536 ,  0.08449176]), done=False), Experience(state=array([ 0.65042843, -0.26100203,  0.07014873,  0.0372845 ,  0.01989229,
        4.49166332,  0.14782161]), action=7, reward=-1, next_state=array([ 0.65317663, -0.34741145,  0.07975452,  0.04221786,  0.01015482,
        3.34579668,  0.05963253]), done=False), Experience(state=array([ 0.712007  , -0.17078816, -0.05073962,  0.02900278,  0.01791766,
        1.96618365,  0.17714984]), action=5, reward=-1, next_state=array([ 0.71154785, -0.17067493, -0.05074493,  0.0278375 ,  0.01339469,
        2.27251062,  0.32883153]), done=False), Experience(state=array([ 0.63642151, -0.14739965, -0.08958433,  0.02872664,  0.01767514,
        9.10634492,  0.84557744]), action=5, reward=-1, next_state=array([ 0.62039808, -0.16524348, -0.08636696,  0.08105077,  0.03445626,
        8.00584549,  0.85360284]), done=False), Experience(state=array([ 0.52927763, -0.81978605,  0.03577838,  0.03111051,  0.01489524,
        3.08853436,  0.16702272]), action=9, reward=-1, next_state=array([ 0.52926024, -0.82143521,  0.14082312,  0.03564608,  0.02587065,
        3.08409573,  0.14405483]), done=False), Experience(state=array([ 0.64803082, -0.16402643,  0.14646509,  0.02198445,  0.01081945,
        4.78787854,  0.0886976 ]), action=7, reward=-1, next_state=array([ 0.64109158, -0.40745991,  0.18213235,  0.37600999,  0.27717771,
       10.36447191,  0.80161477]), done=False), Experience(state=array([ 0.52441722, -0.82075437,  0.23171247,  0.03985057,  0.02476453,
        2.71671183,  0.10592954]), action=8, reward=100, next_state=array([ 0.5268376 , -0.81353627,  0.10203447,  0.07173167,  0.08767453,
        3.01409074,  0.11916569]), done=True), Experience(state=array([ 0.70929261, -0.15373958, -0.05309598,  0.03224092,  0.02048089,
        2.67178453,  0.12771022]), action=5, reward=-1, next_state=array([ 0.71119889, -0.1502347 , -0.04999161,  0.03231389,  0.01915105,
        3.58297863,  0.10764512]), done=False), Experience(state=array([ 0.50754027, -0.39181389,  0.15968028,  0.02506484,  0.01115198,
        1.71026663,  0.12106916]), action=3, reward=-1, next_state=array([ 0.49333461, -0.38791862,  0.15897306,  0.05712469,  0.02501372,
        0.95363362,  0.11227411]), done=False), Experience(state=array([ 0.52264628, -0.8222477 , -0.01760393,  0.02826866,  0.01870062,
        0.84957014,  0.11323869]), action=9, reward=-1, next_state=array([ 0.52869884, -0.82245679,  0.13455064,  0.06207069,  0.02284128,
        1.44957687,  0.11082539]), done=False), Experience(state=array([ 0.69075277, -0.14122997, -0.01792165,  0.0216665 ,  0.01290491,
        2.83377164,  0.12815745]), action=5, reward=-1, next_state=array([ 0.69097766, -0.14095066, -0.01684635,  0.02627283,  0.01574393,
        2.97615202,  0.16036539]), done=False), Experience(state=array([ 0.72135989, -0.2866194 , -0.06234962,  0.02209473,  0.01400392,
        2.37624565,  0.04815693]), action=5, reward=-1, next_state=array([ 0.71999775, -0.28705074, -0.06251319,  0.03328758,  0.02213802,
        1.77625694,  0.05874565]), done=False), Experience(state=array([ 0.68305016, -0.24024845,  0.11619805,  0.02365398,  0.01123622,
        2.4840488 ,  0.06687012]), action=4, reward=-1, next_state=array([ 0.68317859, -0.23962609,  0.03231735,  0.05022888,  0.09046277,
        2.43429532,  0.08289671]), done=False), Experience(state=array([ 0.76640295, -0.10526649, -0.07160539,  0.03634445,  0.0241062 ,
        1.74073504,  0.07943398]), action=4, reward=-1, next_state=array([ 0.76630471, -0.10468479, -0.07158034,  0.02955904,  0.0189621 ,
        1.52051822,  0.07797525]), done=False), Experience(state=array([ 0.7214984 , -0.13051624, -0.03900934,  0.03150905,  0.01614475,
        2.41755048,  0.07046934]), action=5, reward=-1, next_state=array([ 0.72732501, -0.12999412,  0.03320008,  0.02966315,  0.0168693 ,
        1.50638718,  0.06540424]), done=False), Experience(state=array([ 0.65529412, -0.41818142,  0.11781025,  0.02615062,  0.01366351,
        1.64552146,  0.07313941]), action=7, reward=-1, next_state=array([ 0.52429549, -0.81925909,  0.23132432,  0.06401354,  0.04790867,
        2.08934519,  0.06154828]), done=False), Experience(state=array([ 0.61373468, -0.15503566,  0.10672334,  0.02132975,  0.01230615,
        8.94568916,  0.13780963]), action=7, reward=-1, next_state=array([ 0.58476591, -0.43675411,  0.11767289,  0.0662194 ,  0.04428195,
        7.74873296,  0.10078558]), done=False), Experience(state=array([ 0.66104867, -0.19278059,  0.12927786,  0.04802679,  0.02272255,
        3.07480802,  0.0512326 ]), action=7, reward=-1, next_state=array([ 0.66417797, -0.1883953 ,  0.13399564,  0.03094894,  0.01368594,
        2.23941323,  0.06493493]), done=False), Experience(state=array([ 0.65252924, -0.17733869,  0.11015189,  0.04720953,  0.01969765,
        3.05898271,  0.05924983]), action=7, reward=-1, next_state=array([ 0.61935695, -0.55060818,  0.16647415,  0.35291132,  0.26020415,
        1.95337297,  0.08243298]), done=False), Experience(state=array([ 3.25012867e-01, -6.49626170e-01, -1.13190736e-01,  2.84054170e-02,
        1.38203179e-02,  2.73281815e+01,  1.57417295e+00]), action=9, reward=-1, next_state=array([ 0.33372969, -0.63646265,  0.03673759,  0.08694216,  0.03246978,
        1.62145005,  0.0988615 ]), done=False), Experience(state=array([ 0.57540223, -0.47861216,  0.08750364,  0.02542206,  0.01333427,
        2.97863847,  0.05297765]), action=7, reward=-1, next_state=array([ 0.577099  , -0.485298  ,  0.08748523,  0.0348082 ,  0.02076405,
        7.69515681,  0.42646436]), done=False), Experience(state=array([ 0.73411259, -0.17247107, -0.12018173,  0.0270201 ,  0.01674638,
        2.00023041,  0.07507943]), action=5, reward=-1, next_state=array([ 0.73707723, -0.17237298, -0.11644971,  0.01857245,  0.00766953,
        2.44083417,  0.09898424]), done=False), Experience(state=array([ 0.52656891, -0.81797569,  0.03308538,  0.02642215,  0.01446898,
        1.36099283,  0.07086781]), action=9, reward=-1, next_state=array([ 0.52850374, -0.81979749,  0.13830541,  0.05028697,  0.02768476,
        1.91207551,  0.04061478]), done=False), Experience(state=array([ 0.72530274, -0.09687486, -0.03617912,  0.02699721,  0.0158044 ,
        3.55297502,  0.08235727]), action=5, reward=-1, next_state=array([ 0.72607312, -0.08685889,  0.02767418,  0.02630575,  0.01975845,
        4.45812345,  0.09219402]), done=False), Experience(state=array([ 0.52769735, -0.82204776,  0.04216605,  0.0239368 ,  0.01816987,
        2.56586046,  0.15838516]), action=9, reward=-1, next_state=array([ 0.53077671, -0.8203553 ,  0.14318134,  0.05484918,  0.02697327,
        2.54415291,  0.16047748]), done=False), Experience(state=array([ 0.52784343, -0.82018286,  0.23169454,  0.04465576,  0.01762219,
        4.03377216,  0.08307074]), action=8, reward=100, next_state=array([ 0.52800966, -0.81922049,  0.22885005,  0.05851014,  0.03097167,
        3.92564055,  0.06983381]), done=True), Experience(state=array([ 0.64572559, -0.17890558,  0.11062943,  0.03708279,  0.01703441,
        3.24623777,  0.04574605]), action=7, reward=-1, next_state=array([ 0.63164899, -0.49548199,  0.16274263,  0.36919106,  0.34257458,
        2.598792  ,  0.12038963]), done=False), Experience(state=array([ 0.71022125, -0.27343174, -0.10470962,  0.02492521,  0.01373058,
        1.75559492,  0.07754823]), action=5, reward=-1, next_state=array([ 0.7102996 , -0.27306736, -0.10368172,  0.02640622,  0.01561388,
        2.02305968,  0.07998861]), done=False), Experience(state=array([ 0.71915384, -0.13555115, -0.02109023,  0.04076995,  0.0261344 ,
        3.64136766,  0.14525247]), action=5, reward=-1, next_state=array([ 0.72845268, -0.14741166,  0.03172109,  0.05286229,  0.03079577,
        1.95448445,  0.11189423]), done=False), Experience(state=array([ 0.76029038, -0.06760069, -0.06737565,  0.01706358,  0.01399529,
        2.48781345,  0.18133165]), action=5, reward=-1, next_state=array([ 7.64365250e-01, -8.91583004e-02, -8.35653793e-05,  9.30161048e-02,
        1.21631194e-01,  2.36585309e+00,  6.82588623e-02]), done=False), Experience(state=array([ 0.79190583, -0.10938927, -0.03139044,  0.02338297,  0.0092621 ,
        2.87563957,  0.09342904]), action=4, reward=-1, next_state=array([ 0.79151265, -0.10920446, -0.03147768,  0.02965462,  0.0190661 ,
        1.81699978,  0.09915072]), done=False), Experience(state=array([ 0.5266992 , -0.82034914,  0.23239092,  0.04650018,  0.02372198,
        1.99150225,  0.08543063]), action=8, reward=100, next_state=array([ 0.52286764, -0.81746292,  0.03357424,  0.07615392,  0.03627588,
        2.44866181,  0.10509209]), done=True), Experience(state=array([ 0.68674187, -0.17234631,  0.14450914,  0.02780086,  0.013061  ,
        3.83608676,  0.14908191]), action=7, reward=-1, next_state=array([ 0.58034539, -0.46554838,  0.06300355,  0.02407872,  0.01221121,
        6.05595267,  0.39183755]), done=False), Experience(state=array([ 0.52548495, -0.82024688,  0.23200446,  0.04033685,  0.02871171,
        2.65357455,  0.10726122]), action=8, reward=100, next_state=array([ 0.53289967, -0.81484417,  0.23205113,  0.02531903,  0.01085179,
        2.53028367,  0.10171932]), done=True), Experience(state=array([ 0.66450388, -0.16317715,  0.10411998,  0.0186973 ,  0.01152315,
        4.52503099,  0.15620175]), action=7, reward=-1, next_state=array([ 5.12805088e-01, -4.67878554e-01,  4.03242105e-02,  3.85518692e-02,
        1.49796829e-02,  1.75265607e+01,  2.14636819e+00]), done=False), Experience(state=array([ 0.6347297 , -0.22954028,  0.03682414,  0.01743531,  0.00868003,
        2.04003234,  0.03474029]), action=4, reward=-1, next_state=array([ 0.6378662 , -0.25074914, -0.02706364,  0.0658662 ,  0.08236006,
        2.23320822,  0.04618822]), done=False), Experience(state=array([ 0.52825374, -0.8215077 ,  0.03799448,  0.03962673,  0.02598411,
        1.22057377,  0.15318744]), action=9, reward=-1, next_state=array([ 0.52932758, -0.82209533,  0.14201568,  0.05075174,  0.0256605 ,
        2.26804797,  0.15073755]), done=False), Experience(state=array([ 0.59288297, -0.18826152,  0.08858662,  0.03029158,  0.01499331,
        1.79752326,  0.06774135]), action=4, reward=-1, next_state=array([ 0.59255349, -0.18911617,  0.08830732,  0.02385014,  0.01303056,
        1.71517635,  0.07001327]), done=False), Experience(state=array([ 0.59142177, -0.14230419,  0.11439243,  0.04538942,  0.0232457 ,
        1.84637341,  0.09920828]), action=7, reward=-1, next_state=array([ 0.4825856 , -0.48781805,  0.10970873,  0.02971727,  0.01872243,
        6.91499015,  0.8211364 ]), done=False), Experience(state=array([ 0.68350247, -0.13726258,  0.09586045,  0.0287143 ,  0.02600472,
       11.39229505,  0.10713355]), action=7, reward=-1, next_state=array([ 0.67940753, -0.18806281,  0.10153179,  0.04872412,  0.0221307 ,
       11.27544242,  0.10439088]), done=False), Experience(state=array([ 0.70247609, -0.13314785, -0.02067351,  0.03580812,  0.02477762,
        3.48949096,  0.10574475]), action=5, reward=-1, next_state=array([ 0.70823714, -0.14076412,  0.02157281,  0.04521456,  0.0281259 ,
        2.04818673,  0.08356017]), done=False), Experience(state=array([ 0.65601802, -0.20004661,  0.1149076 ,  0.03840076,  0.0190616 ,
        4.80671035,  0.07013935]), action=7, reward=-1, next_state=array([ 0.65455984, -0.44218364,  0.14339675,  0.33530614,  0.24791287,
        4.69637843,  0.08895299]), done=False), Experience(state=array([ 0.66101552, -0.22475229,  0.11548943,  0.0341447 ,  0.01952821,
        2.24132192,  0.06191514]), action=7, reward=-1, next_state=array([ 0.65315383, -0.4956804 ,  0.15400374,  0.24854971,  0.25307314,
        7.91970154,  0.24448931]), done=False), Experience(state=array([ 0.62065329, -0.17779985,  0.11310383,  0.02723688,  0.01369078,
        4.56474867,  0.05054632]), action=7, reward=-1, next_state=array([ 0.57092267, -0.63143553,  0.06421822,  0.03294766,  0.0222906 ,
       15.8696735 ,  1.7962018 ]), done=False), Experience(state=array([ 0.6928165 , -0.16913082, -0.02124731,  0.02481921,  0.01446476,
        3.92012415,  0.04873364]), action=5, reward=-1, next_state=array([ 0.71314161, -0.17579448,  0.04229394,  0.02846249,  0.0199641 ,
        2.53713301,  0.08102807]), done=False), Experience(state=array([ 0.65522581, -0.16758278,  0.15172874,  0.02838921,  0.01545679,
        4.13919563,  0.07423657]), action=7, reward=-1, next_state=array([ 0.64546552, -0.40250698,  0.1832963 ,  0.5435863 ,  0.37018667,
       13.57205541,  0.54377072]), done=False), Experience(state=array([ 0.67771381, -0.30956877, -0.11056652,  0.02869996,  0.02130084,
        2.23068404,  0.06377917]), action=5, reward=-1, next_state=array([ 0.6793011 , -0.30964991, -0.10883581,  0.03448832,  0.01612842,
        3.08166389,  0.07019709]), done=False), Experience(state=array([ 0.68354669, -0.2357191 ,  0.1093757 ,  0.03788051,  0.01929566,
        3.10725354,  0.06549299]), action=7, reward=-1, next_state=array([ 0.66761926, -0.50648665,  0.15809777,  0.31140226,  0.27567349,
        4.76724716,  0.17300744]), done=False), Experience(state=array([ 6.40817749e-01, -1.44490903e-01, -9.33373899e-04,  2.22991621e-02,
        9.89534834e-03,  1.46743843e+00,  1.26798551e-01]), action=5, reward=-1, next_state=array([ 6.41313096e-01, -1.43758631e-01, -8.57212458e-04,  2.62498834e-02,
        1.70716369e-02,  1.90581650e+00,  2.87396927e-01]), done=False), Experience(state=array([ 0.52928521, -0.82164967,  0.03773089,  0.02300175,  0.01486092,
        1.76048644,  0.07860498]), action=9, reward=-1, next_state=array([ 0.53600364, -0.81578025,  0.23897355,  0.19447652,  0.04206883,
        1.56336029,  0.09774182]), done=False), Experience(state=array([ 0.40426202, -0.61959585,  0.00652934,  0.02853105,  0.01514255,
        3.55846149,  0.23049269]), action=9, reward=-1, next_state=array([ 0.40359353, -0.61067432,  0.15749876,  0.03080034,  0.01493755,
        3.68521546,  0.09466879]), done=False), Experience(state=array([ 0.68026642, -0.23581728, -0.10888909,  0.02622059,  0.02035977,
        2.29189269,  0.04123908]), action=4, reward=-1, next_state=array([ 0.68519717, -0.18204053, -0.10467165,  0.05284768,  0.0296732 ,
        2.11220898,  0.06104504]), done=False), Experience(state=array([ 0.52654677, -0.819306  ,  0.23050593,  0.04125753,  0.03033549,
        2.74544625,  0.12317574]), action=8, reward=100, next_state=array([ 0.52935957, -0.81786761,  0.23110366,  0.02716487,  0.0117961 ,
        2.59540649,  0.09983652]), done=True), Experience(state=array([ 0.69214532, -0.27295132, -0.10293338,  0.02439375,  0.014122  ,
        0.96930734,  0.06206995]), action=5, reward=-1, next_state=array([ 0.69187722, -0.27280034, -0.10280848,  0.02878466,  0.01722177,
        2.20291728,  0.06893068]), done=False), Experience(state=array([ 0.52608527, -0.82173536,  0.23267936,  0.0492421 ,  0.02414858,
        1.70117341,  0.10385769]), action=8, reward=100, next_state=array([ 0.53018719, -0.81838191,  0.23301145,  0.03712969,  0.01708567,
        1.78839879,  0.10691901]), done=True), Experience(state=array([ 0.66243607, -0.19009451,  0.11176123,  0.0461357 ,  0.02080035,
        4.39645374,  0.0423219 ]), action=7, reward=-1, next_state=array([ 0.6303984 , -0.55218173,  0.16820593,  0.14055654,  0.15584081,
        5.12300531,  0.15909556]), done=False), Experience(state=array([ 0.52496608, -0.81890092,  0.03313374,  0.04598216,  0.02557341,
        4.37868447,  0.08253226]), action=9, reward=-1, next_state=array([ 0.53270295, -0.81765578,  0.13857953,  0.02915916,  0.01642526,
        2.37014644,  0.05533477]), done=False), Experience(state=array([ 0.71100999, -0.08852843, -0.04003348,  0.02079519,  0.01302266,
        1.75715301,  0.0559366 ]), action=5, reward=-1, next_state=array([ 0.70482056, -0.09489568,  0.05442413,  0.03016961,  0.01646781,
        2.16526186,  0.07650266]), done=False), Experience(state=array([ 0.64521172, -0.16109201,  0.11040421,  0.08154059,  0.03932946,
        3.62258522,  0.06194013]), action=7, reward=-1, next_state=array([ 0.60746007, -0.5974635 ,  0.17416463,  0.2124115 ,  0.26445367,
        5.16018831,  0.20217902]), done=False), Experience(state=array([ 0.71463114, -0.27138752, -0.10798272,  0.02302847,  0.01232385,
        1.71266646,  0.06193854]), action=4, reward=-1, next_state=array([ 0.72764675, -0.22148985, -0.11011892,  0.0264885 ,  0.01343191,
        2.18773339,  0.05728017]), done=False), Experience(state=array([ 0.67437808, -0.1839879 , -0.04907864,  0.02464364,  0.0158596 ,
        2.82475564,  0.38771338]), action=5, reward=-1, next_state=array([ 0.67204861, -0.17927902, -0.0492857 ,  0.02492263,  0.01216466,
        5.30376943,  0.55621604]), done=False), Experience(state=array([ 6.75737279e-01, -2.69342929e-01,  2.72120889e-04,  3.11634922e-02,
        1.88438096e-02,  2.87044330e+00,  5.19718891e-02]), action=4, reward=-1, next_state=array([ 0.67174885, -0.22106118, -0.0631735 ,  0.02506299,  0.01403258,
        2.00827036,  0.04682301]), done=False), Experience(state=array([ 0.56859664, -0.32369586, -0.10484098,  0.03447668,  0.01896825,
        1.17525912,  0.05265228]), action=4, reward=-1, next_state=array([ 0.53694041, -0.32724068, -0.10206109,  0.04309875,  0.0302781 ,
        1.59072125,  0.04911036]), done=False), Experience(state=array([ 0.70388491, -0.16202495, -0.04907078,  0.02813706,  0.01653479,
        1.41110501,  0.13982654]), action=5, reward=-1, next_state=array([ 6.93132121e-01, -1.52411703e-01,  1.74049659e-03,  8.11955020e-02,
        8.15532059e-02,  1.22781375e+01,  9.59830551e-02]), done=False), Experience(state=array([ 7.33678091e-01, -1.58211739e-01,  6.47037769e-04,  2.73962325e-02,
        1.56652214e-02,  3.11030781e+00,  1.12201999e-01]), action=5, reward=-1, next_state=array([ 7.33595291e-01, -1.58459590e-01,  6.45661592e-04,  3.65048762e-02,
        1.97100180e-02,  2.84408682e+00,  1.35390106e-01]), done=False), Experience(state=array([ 0.68317456, -0.1606441 ,  0.10029276,  0.03538801,  0.02145963,
        1.66976508,  0.12478235]), action=4, reward=-1, next_state=array([ 0.68111436, -0.16319159,  0.01128135,  0.0209805 ,  0.01186227,
        1.80571312,  0.11411546]), done=False), Experience(state=array([ 0.6255658 , -0.24456438,  0.11210632,  0.04280857,  0.01920696,
        1.62777256,  0.05280518]), action=4, reward=-1, next_state=array([ 0.62733766, -0.24303979,  0.05827451,  0.08312983,  0.0905082 ,
        2.96007424,  0.05006267]), done=False), Experience(state=array([ 0.52987644, -0.82039025,  0.04011794,  0.0369716 ,  0.02145143,
        4.10582644,  0.15113617]), action=9, reward=-1, next_state=array([ 0.52775935, -0.82333422,  0.14354579,  0.06412447,  0.03152912,
        4.40030299,  0.15106486]), done=False), Experience(state=array([ 0.65595785, -0.29744686, -0.04381179,  0.01871451,  0.01177743,
        1.74547753,  0.05982792]), action=5, reward=-1, next_state=array([ 0.66325452, -0.29488812,  0.1108275 ,  0.06335775,  0.04492165,
        2.46378728,  0.07429353]), done=False), Experience(state=array([ 0.58213319, -0.19076855,  0.10842128,  0.03342383,  0.01484072,
        2.48425889,  0.06352316]), action=4, reward=-1, next_state=array([ 0.57880036, -0.19165404,  0.04668689,  0.05924704,  0.07162262,
        2.18209151,  0.06620619]), done=False), Experience(state=array([ 0.52829895, -0.81872954,  0.23228211,  0.03024771,  0.01787041,
        3.73807321,  0.10754416]), action=8, reward=100, next_state=array([ 0.51850308, -0.8275438 ,  0.0340862 ,  0.10559437,  0.07863496,
        2.91278986,  0.15702792]), done=True), Experience(state=array([ 0.7248311 , -0.13211689, -0.07056153,  0.02341814,  0.01192337,
        2.38484116,  0.03952841]), action=4, reward=-1, next_state=array([ 0.72320784, -0.0825401 , -0.06888516,  0.03016267,  0.01730808,
        2.83484404,  0.04853183]), done=False), Experience(state=array([ 0.71493063, -0.08960841, -0.03968937,  0.03644702,  0.018239  ,
        2.01976368,  0.0610329 ]), action=5, reward=-1, next_state=array([ 0.71101733, -0.08668962,  0.0487107 ,  0.02963279,  0.01988118,
        1.92832014,  0.07018478]), done=False), Experience(state=array([ 0.65270902, -0.22246673, -0.11191682,  0.02882548,  0.01626815,
        1.44415311,  0.05583019]), action=4, reward=-1, next_state=array([ 0.6526412 , -0.22237474, -0.11214375,  0.0231441 ,  0.0107051 ,
        1.25355661,  0.04955904]), done=False), Experience(state=array([ 0.41787793, -0.65065627, -0.01565476,  0.01801303,  0.0090735 ,
        1.68804944,  0.09375162]), action=9, reward=-1, next_state=array([ 0.42294544, -0.64599872,  0.13383189,  0.05621271,  0.02488616,
        1.75286594,  0.06980359]), done=False), Experience(state=array([ 0.72238487, -0.11596854,  0.10036675,  0.0182691 ,  0.00968663,
        2.75076086,  0.06963288]), action=4, reward=-1, next_state=array([ 0.72748025, -0.12486214,  0.00657749,  0.03718953,  0.01982297,
        3.28962305,  0.05642138]), done=False), Experience(state=array([ 0.81614818, -0.45000034,  0.08610698,  0.01906792,  0.01166033,
        1.31910387,  0.0879023 ]), action=3, reward=-1, next_state=array([ 0.81685743, -0.45078236,  0.0868171 ,  0.02376204,  0.0138949 ,
        2.71748377,  0.0686039 ]), done=False), Experience(state=array([ 0.80674115, -0.46189139,  0.09519876,  0.02314491,  0.01759261,
        1.13491888,  0.05557595]), action=3, reward=-1, next_state=array([ 0.80783423, -0.46166275,  0.09573967,  0.02492683,  0.01330812,
        1.48049279,  0.05875681]), done=False), Experience(state=array([ 0.67999849, -0.24198143,  0.08133175,  0.02630015,  0.01137313,
        1.85468861,  0.05636349]), action=4, reward=-1, next_state=array([ 0.68441034, -0.24989571,  0.03625607,  0.09361152,  0.10984582,
        2.02375391,  0.06187679]), done=False), Experience(state=array([ 0.68281719, -0.12800745,  0.09678887,  0.03614898,  0.01666227,
       11.50140982,  0.10923929]), action=7, reward=-1, next_state=array([ 0.67340745, -0.13503574,  0.104837  ,  0.0319641 ,  0.02042623,
       12.93376882,  0.095248  ]), done=False), Experience(state=array([ 0.6931971 , -0.39455069,  0.13914267,  0.0243833 ,  0.0150385 ,
        1.60342039,  0.05507586]), action=7, reward=-1, next_state=array([ 0.69149887, -0.39404028,  0.13802847,  0.02919069,  0.01392044,
        2.00278283,  0.06160568]), done=False), Experience(state=array([ 0.65856548, -0.1304329 , -0.09168825,  0.02131422,  0.01019472,
        2.68054582,  0.16352656]), action=5, reward=-1, next_state=array([ 0.67420683, -0.14620455,  0.03862951,  0.02590119,  0.01405254,
        1.42675335,  0.09752913]), done=False), Experience(state=array([ 0.64195121, -0.21054349, -0.12382146,  0.02110574,  0.01121594,
        1.79027073,  0.07163895]), action=5, reward=-1, next_state=array([ 0.64247803, -0.2107197 , -0.12367942,  0.02352254,  0.01387941,
        2.50178157,  0.06652623]), done=False), Experience(state=array([ 0.65144125, -0.15651439, -0.08764179,  0.01940658,  0.01410365,
        1.68861128,  0.1400947 ]), action=5, reward=-1, next_state=array([ 0.65740098, -0.16390574, -0.02833229,  0.0291066 ,  0.01505285,
        2.28042429,  0.14085758]), done=False), Experience(state=array([ 0.70061348, -0.09399152, -0.0396226 ,  0.0322392 ,  0.01517505,
        2.47343014,  0.06029502]), action=5, reward=-1, next_state=array([ 0.69585774, -0.08884274,  0.05203363,  0.03117955,  0.02054975,
        2.72825364,  0.0609991 ]), done=False), Experience(state=array([ 0.69782188, -0.37504566,  0.08737391,  0.03447269,  0.01580962,
        2.37550441,  0.06504811]), action=3, reward=-1, next_state=array([ 0.69776666, -0.37494468,  0.08723637,  0.03059167,  0.0131093 ,
        1.79722373,  0.05430063]), done=False), Experience(state=array([ 0.62596698, -0.22739993,  0.14588596,  0.04450295,  0.01941714,
        4.30850194,  0.06171981]), action=7, reward=-1, next_state=array([ 0.62634608, -0.41652353,  0.17930738,  0.25059277,  0.27563012,
        7.60617276,  0.30530144]), done=False), Experience(state=array([ 0.64455433, -0.34445749, -0.10361136,  0.01762795,  0.01206668,
        1.62450347,  0.04266859]), action=4, reward=-1, next_state=array([ 0.64381348, -0.34518938, -0.10369884,  0.02173542,  0.01325693,
        2.1804741 ,  0.03427102]), done=False), Experience(state=array([ 0.66546498, -0.15708005,  0.15170279,  0.02595497,  0.01432112,
        3.91314963,  0.08577478]), action=7, reward=-1, next_state=array([ 0.65594667, -0.38905632,  0.18050705,  0.55855373,  0.3903    ,
        9.65825933,  0.77026079]), done=False), Experience(state=array([ 0.64440857, -0.13960077,  0.14657275,  0.02423682,  0.01191561,
        4.66514707,  0.054085  ]), action=7, reward=-1, next_state=array([ 0.63342505, -0.43882531,  0.19194039,  0.26553531,  0.22826891,
        4.18718807,  0.24509259]), done=False), Experience(state=array([ 0.65799561, -0.23816731,  0.03904662,  0.02358923,  0.01707682,
        1.20453351,  0.0307931 ]), action=4, reward=-1, next_state=array([ 0.66161975, -0.25928735, -0.11248889,  0.03159054,  0.01620066,
        3.70270665,  0.0404615 ]), done=False), Experience(state=array([ 0.52796343, -0.82105603,  0.039189  ,  0.04657774,  0.03212938,
        2.74987549,  0.11219218]), action=9, reward=-1, next_state=array([ 0.53346944, -0.81919891,  0.19331894,  0.04437321,  0.02297336,
        1.7038129 ,  0.09706794]), done=False), Experience(state=array([ 0.63471269, -0.17185318,  0.04958183,  0.03740579,  0.02186042,
        2.96831508,  0.05247481]), action=7, reward=-1, next_state=array([ 0.6271453 , -0.35928667,  0.0659503 ,  0.04830082,  0.02862528,
        3.31449847,  0.05958983]), done=False), Experience(state=array([ 0.60705042, -0.17644706, -0.01408228,  0.02543663,  0.01285754,
        1.72775637,  0.11635789]), action=3, reward=-1, next_state=array([ 0.60778144, -0.17876363,  0.01034374,  0.02511571,  0.0107843 ,
        2.2355188 ,  0.09556756]), done=False), Experience(state=array([ 0.67042589, -0.32710127, -0.01956628,  0.02009841,  0.00931355,
        1.58003916,  0.04957835]), action=3, reward=-1, next_state=array([ 0.66837584, -0.32764225, -0.02039564,  0.02416716,  0.01379423,
        2.56676294,  0.07128362]), done=False), Experience(state=array([ 0.81664429, -0.45042007,  0.08712028,  0.02323137,  0.01311227,
        1.02877648,  0.05782922]), action=3, reward=-1, next_state=array([ 0.7496418 , -0.36812904,  0.08002786,  0.0941476 ,  0.061715  ,
        2.64951558,  0.03664289]), done=False), Experience(state=array([ 0.52721036, -0.81913361,  0.03490605,  0.01767605,  0.01162583,
        2.63787077,  0.06599694]), action=9, reward=-1, next_state=array([ 0.52905098, -0.82156617,  0.14061322,  0.05017369,  0.02408475,
        1.589183  ,  0.06550941]), done=False), Experience(state=array([ 0.66002685, -0.14027793,  0.09766879,  0.02955109,  0.0162735 ,
       11.52819852,  0.12446447]), action=7, reward=-1, next_state=array([ 0.66187024, -0.13544675,  0.09853644,  0.02375149,  0.01314002,
       10.71052188,  0.13040348]), done=False), Experience(state=array([ 0.61736518, -0.17915927,  0.10974269,  0.03261195,  0.0186176 ,
        3.38669534,  0.15992508]), action=4, reward=-1, next_state=array([ 0.62369358, -0.18968727,  0.04796642,  0.02880628,  0.01858271,
        2.28114968,  0.48616475]), done=False), Experience(state=array([ 0.69417484, -0.16256381,  0.10948568,  0.02606183,  0.01391857,
        5.68249323,  0.1774648 ]), action=7, reward=-1, next_state=array([ 0.5745426 , -0.47135706,  0.05386795,  0.01892366,  0.00832952,
        5.78823731,  0.37340459]), done=False), Experience(state=array([ 0.52418619, -0.82266597,  0.23017424,  0.03795179,  0.01980869,
       13.74182303,  0.25409937]), action=8, reward=100, next_state=array([ 5.29308896e-01, -8.16809758e-01,  2.32475975e-01,  2.05473216e-02,
        9.97616643e-03,  1.20954876e+01,  2.24744304e-01]), done=True), Experience(state=array([ 0.52953706, -0.81866819,  0.23312375,  0.03091849,  0.01299165,
        3.35039587,  0.09692892]), action=8, reward=100, next_state=array([ 0.52503674, -0.8179576 ,  0.03160855,  0.03423063,  0.01820691,
        4.06795805,  0.07794243]), done=True), Experience(state=array([ 0.65123429, -0.17614533,  0.06404687,  0.02355824,  0.01185301,
        1.1963175 ,  0.08253053]), action=4, reward=-1, next_state=array([ 0.64889005, -0.17308114, -0.06351834,  0.02705558,  0.01579168,
        5.44128984,  0.48843729]), done=False), Experience(state=array([ 0.60230678, -0.13613561,  0.11598623,  0.02949988,  0.01430006,
        1.69122783,  0.12811193]), action=7, reward=-1, next_state=array([ 0.48866539, -0.4824634 ,  0.11638503,  0.0240247 ,  0.0141928 ,
        8.33679506,  0.77210068]), done=False), Experience(state=array([ 0.70910508, -0.13346841,  0.10662372,  0.0365926 ,  0.01970775,
        5.34297158,  0.15385077]), action=7, reward=-1, next_state=array([ 0.58094241, -0.47210252,  0.05571616,  0.03040557,  0.01701005,
        5.39074445,  0.4575656 ]), done=False), Experience(state=array([ 0.63819414, -0.16536223,  0.03265578,  0.03373026,  0.02022981,
        2.38378757,  0.11290655]), action=5, reward=-1, next_state=array([ 0.63850673, -0.16312868,  0.0336188 ,  0.05230404,  0.02390162,
        1.61317561,  0.12036917]), done=False), Experience(state=array([ 0.63105121, -0.23162881,  0.11586992,  0.02198968,  0.01718548,
        2.16745518,  0.05871774]), action=4, reward=-1, next_state=array([ 0.63073814, -0.23497563,  0.05321426,  0.06098468,  0.07399802,
        1.87853756,  0.05759316]), done=False), Experience(state=array([ 0.65843802, -0.28825395,  0.11534051,  0.03053764,  0.01455116,
        1.68040653,  0.05940355]), action=4, reward=-1, next_state=array([ 0.65700208, -0.29198699,  0.06172589,  0.05855633,  0.09348592,
        2.75427691,  0.03931403]), done=False), Experience(state=array([ 0.61527378, -0.13353397,  0.08396919,  0.03737736,  0.02131983,
        4.00924789,  0.07682186]), action=7, reward=-1, next_state=array([ 0.60994108, -0.32529742,  0.09142824,  0.02689546,  0.01427206,
        2.41656232,  0.04615327]), done=False), Experience(state=array([ 0.79099074, -0.10567134, -0.03036554,  0.02881654,  0.01688942,
        2.13507825,  0.05937695]), action=5, reward=-1, next_state=array([ 0.79097235, -0.10663687, -0.03032237,  0.01712395,  0.00869536,
        1.96208498,  0.07023443]), done=False), Experience(state=array([ 0.6797788 , -0.16141157,  0.04682518,  0.02845065,  0.01689949,
        3.27812896,  0.06075025]), action=7, reward=-1, next_state=array([ 0.68394264, -0.30216223,  0.06312128,  0.06378024,  0.04278133,
        2.47588438,  0.06563612]), done=False), Experience(state=array([ 0.69435187, -0.2510386 , -0.10762191,  0.02617519,  0.01685341,
        3.03015556,  0.03708188]), action=5, reward=-1, next_state=array([ 0.69452546, -0.25127151, -0.10787179,  0.01935516,  0.01509623,
        2.62084084,  0.03686313]), done=False), Experience(state=array([ 0.68592225, -0.17558222,  0.11107352,  0.02316442,  0.01339666,
        2.05112477,  0.06723459]), action=4, reward=-1, next_state=array([ 0.7043155 , -0.1460327 , -0.03296815,  0.03409667,  0.02117738,
        7.46617134,  0.69169517]), done=False), Experience(state=array([ 6.80308467e-01, -1.14327109e-01, -7.87820335e-02,  1.87955485e-02,
        1.14296735e-02,  1.50488846e+01,  3.49847650e-01]), action=5, reward=-1, next_state=array([ 0.66204601, -0.11545542, -0.07560612,  0.03111674,  0.01542813,
        7.46621783,  0.13503798]), done=False), Experience(state=array([ 0.69563702, -0.16139336, -0.02221833,  0.02520738,  0.01364861,
        2.40835888,  0.09663096]), action=5, reward=-1, next_state=array([ 0.70983436, -0.16402939,  0.04184449,  0.04521306,  0.02802994,
        2.05453053,  0.10400873]), done=False), Experience(state=array([ 0.66571147, -0.14618772, -0.11917625,  0.03144683,  0.0184445 ,
        2.35925068,  0.03766692]), action=5, reward=-1, next_state=array([ 0.66566704, -0.14568807, -0.11783382,  0.02607588,  0.01676978,
        2.39107373,  0.054835  ]), done=False), Experience(state=array([ 0.69629564, -0.15026682, -0.02109397,  0.03446463,  0.02492652,
        2.14500436,  0.09501847]), action=5, reward=-1, next_state=array([ 0.70548332, -0.15780226,  0.03253243,  0.04181568,  0.02875563,
        1.64627708,  0.06018401]), done=False), Experience(state=array([ 0.75057667, -0.34422204,  0.10687768,  0.02885487,  0.014014  ,
        1.68172389,  0.04826502]), action=3, reward=-1, next_state=array([ 0.74826326, -0.3525449 ,  0.21859197,  0.03551484,  0.02164495,
        1.22940763,  0.04669286]), done=False), Experience(state=array([ 0.4398458 , -0.64811797,  0.03566076,  0.03684843,  0.019345  ,
        1.53387941,  0.07106405]), action=9, reward=-1, next_state=array([ 0.44277952, -0.64008696,  0.18839631,  0.05028683,  0.01803975,
        1.36543658,  0.06373175]), done=False), Experience(state=array([ 0.70406373, -0.22732777, -0.04238732,  0.02447907,  0.01122601,
        0.89199205,  0.06137202]), action=4, reward=-1, next_state=array([ 0.71377069, -0.21932928, -0.06219516,  0.02784458,  0.01417661,
        1.42606268,  0.06441582]), done=False), Experience(state=array([ 0.63832527, -0.19691705, -0.00541231,  0.04010936,  0.02583314,
        1.74475165,  0.07494561]), action=4, reward=-1, next_state=array([ 0.69019642, -0.18834674, -0.00270695,  0.03468609,  0.02851352,
        2.68720242,  0.07172706]), done=False), Experience(state=array([ 0.7511373 , -0.14293192,  0.10207883,  0.02914714,  0.01266256,
        1.81385884,  0.04725546]), action=4, reward=-1, next_state=array([ 0.76455709, -0.1279398 ,  0.02548417,  0.03162617,  0.0148458 ,
        2.06992041,  0.05990002]), done=False), Experience(state=array([ 0.42718463, -0.6498402 ,  0.03594655,  0.03189554,  0.02096306,
        1.87241096,  0.08743872]), action=9, reward=-1, next_state=array([ 0.43129421, -0.64145181,  0.18720896,  0.0704817 ,  0.03126434,
        2.54329771,  0.07359145]), done=False), Experience(state=array([ 0.60699683, -0.28019627,  0.03952588,  0.01714674,  0.01233337,
        1.33979652,  0.04812525]), action=4, reward=-1, next_state=array([ 0.60804383, -0.27801457, -0.04733367,  0.08797106,  0.14708494,
        2.11828824,  0.07223063]), done=False), Experience(state=array([ 0.64369673, -0.26300821,  0.04122233,  0.03299061,  0.01950225,
        2.28341512,  0.06966456]), action=4, reward=-1, next_state=array([ 0.60522833, -0.2568685 , -0.03868746,  0.04673718,  0.02976336,
        2.03686299,  0.06176361]), done=False), Experience(state=array([ 0.63803842, -0.16270613, -0.08440684,  0.0221864 ,  0.01373851,
        1.52024562,  0.11189847]), action=5, reward=-1, next_state=array([ 0.63876829, -0.16531834, -0.03478047,  0.05401594,  0.0891771 ,
        1.10646375,  0.11114201]), done=False), Experience(state=array([ 0.62446089, -0.19417785, -0.12344222,  0.02727138,  0.01512309,
        2.91530573,  0.09858329]), action=5, reward=-1, next_state=array([ 0.62385312, -0.19656487, -0.11560362,  0.08004582,  0.08253016,
        2.62708817,  0.06760938]), done=False), Experience(state=array([ 0.62722735, -0.16243994,  0.04252968,  0.03136922,  0.02155693,
        3.16763064,  0.07969351]), action=7, reward=-1, next_state=array([ 0.63497088, -0.32891895,  0.06430632,  0.04978319,  0.03158997,
        2.62315735,  0.07784941]), done=False), Experience(state=array([ 0.68729111, -0.25573399,  0.12874437,  0.03127162,  0.01414073,
        3.57310054,  0.05841278]), action=7, reward=-1, next_state=array([ 0.68771161, -0.25385879,  0.12959206,  0.02558614,  0.01427812,
        2.62199469,  0.06706205]), done=False), Experience(state=array([ 0.80349687, -0.09881995, -0.02966503,  0.04066871,  0.01968893,
        2.91377001,  0.05972132]), action=5, reward=-1, next_state=array([ 0.80037262, -0.1058395 , -0.02766177,  0.03657114,  0.02317214,
        2.10185076,  0.0936073 ]), done=False), Experience(state=array([ 0.53019935, -0.82345484,  0.04307384,  0.03663639,  0.02304422,
        3.34154802,  0.19147419]), action=9, reward=-1, next_state=array([ 0.51018134, -0.8432965 ,  0.13731214,  0.07776516,  0.05499002,
        1.9142724 ,  0.17687108]), done=False), Experience(state=array([ 0.40241498, -0.61962454,  0.03782832,  0.04438379,  0.01958046,
        6.51818252,  0.25785293]), action=9, reward=-1, next_state=array([ 0.40101142, -0.61111815,  0.18790698,  0.02856884,  0.0131562 ,
        1.94376954,  0.07523207]), done=False), Experience(state=array([ 0.63538048, -0.26951076, -0.07941932,  0.02266795,  0.01634791,
        1.39875608,  0.08129148]), action=5, reward=-1, next_state=array([ 0.63889663, -0.27585565, -0.05025159,  0.05462751,  0.07121435,
        2.8551963 ,  0.04864242]), done=False), Experience(state=array([ 0.62706943, -0.37036911,  0.07223744,  0.03284075,  0.01892687,
        2.16620855,  0.0361082 ]), action=7, reward=-1, next_state=array([ 0.62687849, -0.37097258,  0.07221626,  0.02163956,  0.01251983,
        2.03870782,  0.0464194 ]), done=False), Experience(state=array([ 0.79541763, -0.44912968,  0.13043707,  0.02245533,  0.01510802,
        1.64178163,  0.0829007 ]), action=3, reward=-1, next_state=array([ 0.79558064, -0.44913724,  0.13058124,  0.01722052,  0.00834358,
        1.71931549,  0.09097886]), done=False), Experience(state=array([ 0.67961587, -0.13212338, -0.04052356,  0.02642056,  0.01246432,
        2.02399663,  0.08764581]), action=5, reward=-1, next_state=array([ 0.67943846, -0.13505544, -0.0396957 ,  0.02119542,  0.01324505,
        1.89109196,  0.08468843]), done=False), Experience(state=array([ 0.64437617, -0.5006549 ,  0.13828841,  0.02692136,  0.01261287,
        2.39403264,  0.12988374]), action=7, reward=-1, next_state=array([ 0.55320986, -0.78993371,  0.23223213,  0.07101959,  0.07386816,
        2.40169709,  0.10110433]), done=False), Experience(state=array([ 0.66245023, -0.14408638,  0.06408867,  0.0216777 ,  0.01259909,
        2.03459408,  0.11238126]), action=7, reward=-1, next_state=array([ 0.53048131, -0.47062103,  0.04354596,  0.02388235,  0.01179664,
       11.34162893,  1.20885735]), done=False), Experience(state=array([ 0.51232921, -0.4018579 ,  0.16883989,  0.01826786,  0.00783847,
        3.3949034 ,  0.11883702]), action=3, reward=-1, next_state=array([ 0.51133026, -0.39959593,  0.1704622 ,  0.0485184 ,  0.02352007,
        3.01396254,  0.13097477]), done=False), Experience(state=array([ 0.66227624, -0.20289102,  0.05332795,  0.02900514,  0.0151139 ,
        1.99456065,  0.06768607]), action=4, reward=-1, next_state=array([ 6.65094262e-01, -1.92324948e-01,  2.16190214e-03,  2.14115653e-01,
        5.94910104e-02,  2.59375796e+00,  7.87501385e-02]), done=False)]